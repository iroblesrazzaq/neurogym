{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/gyyang/neurogym/blob/master/examples/demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "heading_collapsed": true,
    "id": "4zW6CU8F69Zp"
   },
   "source": [
    "## TOML-based configuration demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "xIE7qx_a7D0e"
   },
   "source": [
    "This notebook demonstrates how an environment and a `Monitor` wrapper can be created using a TOML-based configuration file. It is based on the example in `demo.ipynb`.\n",
    "\n",
    "We will train a network on the `GoNogo-v0` task using the A2C algorithm [Mnih et al. 2016](https://arxiv.org/abs/1602.01783) implemented in the [stable-baselines3](https://stable-baselines3.readthedocs.io/en/master/) toolbox, and plot the results. You can change the settings in `conf.toml` to see how it affects the environment. You can easily change the code to train a network on any other available task or using a different algorithm (e.g. ACER, PPO2)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k3YKMoHkR2xL"
   },
   "source": [
    "### Installation on google colab\n",
    "\n",
    "Uncomment and execute cell below if running on google colab.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "hidden": true,
    "id": "Mp-K8wKGtBoE",
    "outputId": "9e2cefb9-2b67-4a3b-e838-5d60749b4b6f"
   },
   "outputs": [],
   "source": [
    "# # Install gymnasium\n",
    "# ! pip install gymnasium\n",
    "# # Install neurogym\n",
    "# ! git clone https://github.com/neurogym/neurogym.git\n",
    "# %cd neurogym/\n",
    "# ! pip install -e .\n",
    "# # Install stable-baselines3\n",
    "# ! pip install stable-baselines3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZllQKETBVXNM"
   },
   "source": [
    "### Explore tasks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 459
    },
    "colab_type": "code",
    "id": "CehSnXXBVMsh",
    "outputId": "06b18bf8-bfaa-4147-bf82-434665284741"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AntiReach-v0\n",
      "Bandit-v0\n",
      "ContextDecisionMaking-v0\n",
      "DawTwoStep-v0\n",
      "DelayComparison-v0\n",
      "DelayMatchCategory-v0\n",
      "DelayMatchSample-v0\n",
      "DelayMatchSampleDistractor1D-v0\n",
      "DelayPairedAssociation-v0\n",
      "DualDelayMatchSample-v0\n",
      "EconomicDecisionMaking-v0\n",
      "GoNogo-v0\n",
      "HierarchicalReasoning-v0\n",
      "IntervalDiscrimination-v0\n",
      "MotorTiming-v0\n",
      "MultiSensoryIntegration-v0\n",
      "Null-v0\n",
      "OneTwoThreeGo-v0\n",
      "PerceptualDecisionMaking-v0\n",
      "PerceptualDecisionMakingDelayResponse-v0\n",
      "PostDecisionWager-v0\n",
      "ProbabilisticReasoning-v0\n",
      "PulseDecisionMaking-v0\n",
      "Reaching1D-v0\n",
      "Reaching1DWithSelfDistraction-v0\n",
      "ReachingDelayResponse-v0\n",
      "ReadySetGo-v0\n",
      "psychopy.RandomDotMotion-v0\n",
      "psychopy.SpatialSuppressMotion-v0\n",
      "psychopy.VisualSearch-v0\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import gymnasium as gym\n",
    "import neurogym as ngym\n",
    "from neurogym.utils import info, plotting\n",
    "info.all_tasks()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jzF5leN1R2xU"
   },
   "source": [
    "### Visualize a single task\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "RaH9CcJdHY5G",
    "outputId": "b55de485-603f-4f73-af74-8cfecdcd3301"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<OrderEnforcing<PassiveEnvChecker<GoNogo>>>\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x480 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "task = 'GoNogo-v0'\n",
    "env = gym.make(task)\n",
    "print(env)\n",
    "fig = plotting.plot_env(\n",
    "    env,\n",
    "    num_steps=100,\n",
    "    # def_act=0,\n",
    "    ob_traces=['Fixation cue', 'NoGo', 'Go'],\n",
    "    # fig_kwargs={'figsize': (12, 12)}\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "h5BdRE6vVjeS"
   },
   "source": [
    "### Explore wrappers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "OqyGbBGRVlhK",
    "outputId": "27a2e15b-5414-4a08-c6db-f66a7fc78b95"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monitor-v0\n",
      "Noise-v0\n",
      "PassAction-v0\n",
      "PassReward-v0\n",
      "RandomGroundTruth-v0\n",
      "ReactionTime-v0\n",
      "ScheduleAttr-v0\n",
      "ScheduleEnvs-v0\n",
      "SideBias-v0\n",
      "TrialHistoryV2-v0\n"
     ]
    }
   ],
   "source": [
    "info.all_wrappers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "k92VZ01IN5bs",
    "outputId": "391cb8e3-36d6-47e7-e71e-166207552475"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'### TrialHistoryV2-v0\\n\\nLogic: Missing description\\n\\n\\n#### Source code #### \\n\\nclass TrialHistoryV2(TrialWrapper):\\n    \"\"\"Change ground truth probability based on previous outcome.\\n\\n    Args:\\n        probs: matrix of probabilities of the current choice conditioned\\n            on the previous. Shape, num-choices x num-choices\\n    \"\"\"\\n\\n    def __init__(self, env, probs=None) -> None:\\n        super().__init__(env)\\n        try:\\n            self.n_ch = len(self.choices)  # max num of choices\\n        except AttributeError as e:\\n            msg = \"TrialHistory requires task to have attribute choices.\"\\n            raise AttributeError(msg) from e\\n        if probs is None:\\n            probs = np.ones((self.n_ch, self.n_ch)) / self.n_ch  # uniform\\n        self.probs = probs\\n        if self.probs.shape != (self.n_ch, self.n_ch):\\n            msg = f\"{self.probs.shape=} should be {self.n_ch, self.n_ch=}.\"\\n            raise ValueError(msg)\\n        self.prev_trial = self.rng.choice(self.n_ch)  # random initialization\\n\\n    def new_trial(self, **kwargs):\\n        probs = kwargs.get(\"probs\", self.probs)\\n        p = probs[self.prev_trial, :]\\n        # Choose ground truth and update previous trial info\\n        self.prev_trial = self.rng.choice(self.n_ch, p=p)\\n        ground_truth = self.choices[self.prev_trial]\\n        kwargs.update({\"ground_truth\": ground_truth, \"probs\": probs})\\n        return self.env.new_trial(**kwargs)  # type: ignore[attr-defined]\\n\\n\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info.info_wrapper('TrialHistoryV2-v0', show_code=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OCFMPbzX38Wj"
   },
   "source": [
    "### Train a network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "code_folding": [],
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 853
    },
    "colab_type": "code",
    "id": "jAxTPbzL38Wl",
    "outputId": "3405476e-8c1b-4aa6-a45a-4206872cb732"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[35mNeurogym\u001b[0m | \u001b[36m2025-03-26@16:47:54\u001b[0m | \u001b[1mLogger configured.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "from neurogym.wrappers import monitor, TrialHistoryV2\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3 import A2C  # ACER, PPO2\n",
    "# task paremters\n",
    "timing = {'fixation': ('constant', 300),\n",
    "          'stimulus': ('constant', 700),\n",
    "          'decision': ('constant', 300)}\n",
    "kwargs = {'dt': 100, 'timing': timing}\n",
    "# wrapper parameters\n",
    "n_ch = 2\n",
    "p = 0.8\n",
    "num_blocks = 2\n",
    "probs = np.array([[p, 1-p], [1-p, p]])  # repeating block\n",
    "\n",
    "# Build the task\n",
    "env = gym.make(task, **kwargs)\n",
    "\n",
    "# Apply the wrapper.\n",
    "# Here, we use a configuration file to load the parameters.\n",
    "env = TrialHistoryV2(env, probs=probs)\n",
    "env = monitor.Monitor(env, conf=\"conf.toml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "--------------------\n",
      "Number of steps:  10.0\n",
      "Average reward:  0.05\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  20.0\n",
      "Average reward:  -0.3\n",
      "--------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 421      |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 1        |\n",
      "|    total_timesteps    | 500      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.677   |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | 0.0105   |\n",
      "|    value_loss         | 0.000344 |\n",
      "------------------------------------\n",
      "--------------------\n",
      "Number of steps:  30.0\n",
      "Average reward:  -0.3\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  40.0\n",
      "Average reward:  0.1\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  50.0\n",
      "Average reward:  -0.3\n",
      "--------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 443      |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 2        |\n",
      "|    total_timesteps    | 1000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.539   |\n",
      "|    explained_variance | -3.6     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | 0.00286  |\n",
      "|    value_loss         | 0.000123 |\n",
      "------------------------------------\n",
      "--------------------\n",
      "Number of steps:  60.0\n",
      "Average reward:  0.7\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  70.0\n",
      "Average reward:  0.85\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  80.0\n",
      "Average reward:  0.15\n",
      "--------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 449      |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 3        |\n",
      "|    total_timesteps    | 1500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.449   |\n",
      "|    explained_variance | -0.0861  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 299      |\n",
      "|    policy_loss        | 0.341    |\n",
      "|    value_loss         | 0.848    |\n",
      "------------------------------------\n",
      "--------------------\n",
      "Number of steps:  90.0\n",
      "Average reward:  0.4\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  100.0\n",
      "Average reward:  0.45\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  110.0\n",
      "Average reward:  0.55\n",
      "--------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 457      |\n",
      "|    iterations         | 400      |\n",
      "|    time_elapsed       | 4        |\n",
      "|    total_timesteps    | 2000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.211   |\n",
      "|    explained_variance | 0.685    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 399      |\n",
      "|    policy_loss        | 0.000229 |\n",
      "|    value_loss         | 1.89e-05 |\n",
      "------------------------------------\n",
      "--------------------\n",
      "Number of steps:  120.0\n",
      "Average reward:  -0.05\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  130.0\n",
      "Average reward:  0.0\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  140.0\n",
      "Average reward:  0.85\n",
      "--------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 441      |\n",
      "|    iterations         | 500      |\n",
      "|    time_elapsed       | 5        |\n",
      "|    total_timesteps    | 2500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.177   |\n",
      "|    explained_variance | -0.0465  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 499      |\n",
      "|    policy_loss        | -0.0378  |\n",
      "|    value_loss         | 0.199    |\n",
      "------------------------------------\n",
      "--------------------\n",
      "Number of steps:  150.0\n",
      "Average reward:  0.1\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  160.0\n",
      "Average reward:  -0.5\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  170.0\n",
      "Average reward:  0.4\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  180.0\n",
      "Average reward:  0.4\n",
      "--------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 446      |\n",
      "|    iterations         | 600      |\n",
      "|    time_elapsed       | 6        |\n",
      "|    total_timesteps    | 3000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0761  |\n",
      "|    explained_variance | -40      |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 599      |\n",
      "|    policy_loss        | -2.2e-05 |\n",
      "|    value_loss         | 1.56e-05 |\n",
      "------------------------------------\n",
      "--------------------\n",
      "Number of steps:  190.0\n",
      "Average reward:  -0.05\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  200.0\n",
      "Average reward:  0.55\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  210.0\n",
      "Average reward:  0.1\n",
      "--------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 441       |\n",
      "|    iterations         | 700       |\n",
      "|    time_elapsed       | 7         |\n",
      "|    total_timesteps    | 3500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.0522   |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 699       |\n",
      "|    policy_loss        | -3.25e-05 |\n",
      "|    value_loss         | 2.91e-05  |\n",
      "-------------------------------------\n",
      "--------------------\n",
      "Number of steps:  220.0\n",
      "Average reward:  -0.5\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  230.0\n",
      "Average reward:  -0.35\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  240.0\n",
      "Average reward:  0.4\n",
      "--------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 449      |\n",
      "|    iterations         | 800      |\n",
      "|    time_elapsed       | 8        |\n",
      "|    total_timesteps    | 4000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0461  |\n",
      "|    explained_variance | -10.4    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 799      |\n",
      "|    policy_loss        | 7.02e-05 |\n",
      "|    value_loss         | 0.000189 |\n",
      "------------------------------------\n",
      "--------------------\n",
      "Number of steps:  250.0\n",
      "Average reward:  -0.2\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  260.0\n",
      "Average reward:  0.25\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  270.0\n",
      "Average reward:  0.25\n",
      "--------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 455      |\n",
      "|    iterations         | 900      |\n",
      "|    time_elapsed       | 9        |\n",
      "|    total_timesteps    | 4500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.194   |\n",
      "|    explained_variance | -0.0506  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 899      |\n",
      "|    policy_loss        | 0.413    |\n",
      "|    value_loss         | 0.445    |\n",
      "------------------------------------\n",
      "--------------------\n",
      "Number of steps:  280.0\n",
      "Average reward:  0.85\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  290.0\n",
      "Average reward:  -0.05\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  300.0\n",
      "Average reward:  0.1\n",
      "--------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 460      |\n",
      "|    iterations         | 1000     |\n",
      "|    time_elapsed       | 10       |\n",
      "|    total_timesteps    | 5000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0926  |\n",
      "|    explained_variance | -34.6    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 999      |\n",
      "|    policy_loss        | -0.0197  |\n",
      "|    value_loss         | 0.266    |\n",
      "------------------------------------\n",
      "--------------------\n",
      "Number of steps:  310.0\n",
      "Average reward:  -0.2\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  320.0\n",
      "Average reward:  0.25\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  330.0\n",
      "Average reward:  0.1\n",
      "--------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 458      |\n",
      "|    iterations         | 1100     |\n",
      "|    time_elapsed       | 11       |\n",
      "|    total_timesteps    | 5500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0714  |\n",
      "|    explained_variance | -56.2    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1099     |\n",
      "|    policy_loss        | 0.0263   |\n",
      "|    value_loss         | 1.07     |\n",
      "------------------------------------\n",
      "--------------------\n",
      "Number of steps:  340.0\n",
      "Average reward:  1.0\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  350.0\n",
      "Average reward:  0.1\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  360.0\n",
      "Average reward:  0.55\n",
      "--------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 461      |\n",
      "|    iterations         | 1200     |\n",
      "|    time_elapsed       | 13       |\n",
      "|    total_timesteps    | 6000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0413  |\n",
      "|    explained_variance | -0.118   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1199     |\n",
      "|    policy_loss        | 0.0102   |\n",
      "|    value_loss         | 0.439    |\n",
      "------------------------------------\n",
      "--------------------\n",
      "Number of steps:  370.0\n",
      "Average reward:  0.7\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  380.0\n",
      "Average reward:  -0.2\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  390.0\n",
      "Average reward:  -0.2\n",
      "--------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 462       |\n",
      "|    iterations         | 1300      |\n",
      "|    time_elapsed       | 14        |\n",
      "|    total_timesteps    | 6500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.00715  |\n",
      "|    explained_variance | -2.64     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1299      |\n",
      "|    policy_loss        | -2.23e-06 |\n",
      "|    value_loss         | 1.05e-05  |\n",
      "-------------------------------------\n",
      "--------------------\n",
      "Number of steps:  400.0\n",
      "Average reward:  0.7\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  410.0\n",
      "Average reward:  1.0\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  420.0\n",
      "Average reward:  0.55\n",
      "--------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 464      |\n",
      "|    iterations         | 1400     |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 7000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0128  |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1399     |\n",
      "|    policy_loss        | 2.97e-05 |\n",
      "|    value_loss         | 0.000361 |\n",
      "------------------------------------\n",
      "--------------------\n",
      "Number of steps:  430.0\n",
      "Average reward:  0.55\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  440.0\n",
      "Average reward:  0.25\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  450.0\n",
      "Average reward:  0.85\n",
      "--------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 462      |\n",
      "|    iterations         | 1500     |\n",
      "|    time_elapsed       | 16       |\n",
      "|    total_timesteps    | 7500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00422 |\n",
      "|    explained_variance | -21      |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1499     |\n",
      "|    policy_loss        | 7.7e-06  |\n",
      "|    value_loss         | 0.000979 |\n",
      "------------------------------------\n",
      "--------------------\n",
      "Number of steps:  460.0\n",
      "Average reward:  0.4\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  470.0\n",
      "Average reward:  0.85\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  480.0\n",
      "Average reward:  0.1\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  490.0\n",
      "Average reward:  0.55\n",
      "--------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 462      |\n",
      "|    iterations         | 1600     |\n",
      "|    time_elapsed       | 17       |\n",
      "|    total_timesteps    | 8000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0202  |\n",
      "|    explained_variance | 0.407    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1599     |\n",
      "|    policy_loss        | 0.00339  |\n",
      "|    value_loss         | 0.911    |\n",
      "------------------------------------\n",
      "--------------------\n",
      "Number of steps:  500.0\n",
      "Average reward:  -0.2\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  510.0\n",
      "Average reward:  0.25\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  520.0\n",
      "Average reward:  0.55\n",
      "--------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 453      |\n",
      "|    iterations         | 1700     |\n",
      "|    time_elapsed       | 18       |\n",
      "|    total_timesteps    | 8500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0201  |\n",
      "|    explained_variance | -0.058   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1699     |\n",
      "|    policy_loss        | 0.00299  |\n",
      "|    value_loss         | 0.194    |\n",
      "------------------------------------\n",
      "--------------------\n",
      "Number of steps:  530.0\n",
      "Average reward:  -0.35\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  540.0\n",
      "Average reward:  0.1\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  550.0\n",
      "Average reward:  0.25\n",
      "--------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 454      |\n",
      "|    iterations         | 1800     |\n",
      "|    time_elapsed       | 19       |\n",
      "|    total_timesteps    | 9000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00888 |\n",
      "|    explained_variance | -5.48    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1799     |\n",
      "|    policy_loss        | 3.11e-06 |\n",
      "|    value_loss         | 1.12e-05 |\n",
      "------------------------------------\n",
      "--------------------\n",
      "Number of steps:  560.0\n",
      "Average reward:  -0.2\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  570.0\n",
      "Average reward:  0.1\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  580.0\n",
      "Average reward:  0.4\n",
      "--------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 456       |\n",
      "|    iterations         | 1900      |\n",
      "|    time_elapsed       | 20        |\n",
      "|    total_timesteps    | 9500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.0174   |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1899      |\n",
      "|    policy_loss        | -3.07e-05 |\n",
      "|    value_loss         | 0.000185  |\n",
      "-------------------------------------\n",
      "--------------------\n",
      "Number of steps:  590.0\n",
      "Average reward:  1.0\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  600.0\n",
      "Average reward:  0.7\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  610.0\n",
      "Average reward:  0.4\n",
      "--------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 456       |\n",
      "|    iterations         | 2000      |\n",
      "|    time_elapsed       | 21        |\n",
      "|    total_timesteps    | 10000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.00904  |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1999      |\n",
      "|    policy_loss        | 3.01e-05  |\n",
      "|    value_loss         | 0.000857  |\n",
      "-------------------------------------\n",
      "--------------------\n",
      "Number of steps:  620.0\n",
      "Average reward:  0.7\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  630.0\n",
      "Average reward:  0.55\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  640.0\n",
      "Average reward:  -0.05\n",
      "--------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 459      |\n",
      "|    iterations         | 2100     |\n",
      "|    time_elapsed       | 22       |\n",
      "|    total_timesteps    | 10500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0102  |\n",
      "|    explained_variance | -11.2    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2099     |\n",
      "|    policy_loss        | 2.17e-05 |\n",
      "|    value_loss         | 0.00113  |\n",
      "------------------------------------\n",
      "--------------------\n",
      "Number of steps:  650.0\n",
      "Average reward:  0.4\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  660.0\n",
      "Average reward:  0.1\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  670.0\n",
      "Average reward:  0.4\n",
      "--------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 461      |\n",
      "|    iterations         | 2200     |\n",
      "|    time_elapsed       | 23       |\n",
      "|    total_timesteps    | 11000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0454  |\n",
      "|    explained_variance | -0.775   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2199     |\n",
      "|    policy_loss        | -0.00813 |\n",
      "|    value_loss         | 0.289    |\n",
      "------------------------------------\n",
      "--------------------\n",
      "Number of steps:  680.0\n",
      "Average reward:  -0.5\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  690.0\n",
      "Average reward:  -0.2\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  700.0\n",
      "Average reward:  0.4\n",
      "--------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 464      |\n",
      "|    iterations         | 2300     |\n",
      "|    time_elapsed       | 24       |\n",
      "|    total_timesteps    | 11500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0137  |\n",
      "|    explained_variance | -20.1    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2299     |\n",
      "|    policy_loss        | 5.27e-06 |\n",
      "|    value_loss         | 2.39e-05 |\n",
      "------------------------------------\n",
      "--------------------\n",
      "Number of steps:  710.0\n",
      "Average reward:  -0.5\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  720.0\n",
      "Average reward:  -0.35\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  730.0\n",
      "Average reward:  0.4\n",
      "--------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 466       |\n",
      "|    iterations         | 2400      |\n",
      "|    time_elapsed       | 25        |\n",
      "|    total_timesteps    | 12000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.0298   |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2399      |\n",
      "|    policy_loss        | -7.31e-06 |\n",
      "|    value_loss         | 2.43e-06  |\n",
      "-------------------------------------\n",
      "--------------------\n",
      "Number of steps:  740.0\n",
      "Average reward:  -0.05\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  750.0\n",
      "Average reward:  0.7\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  760.0\n",
      "Average reward:  -0.05\n",
      "--------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 467      |\n",
      "|    iterations         | 2500     |\n",
      "|    time_elapsed       | 26       |\n",
      "|    total_timesteps    | 12500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.121   |\n",
      "|    explained_variance | -0.144   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2499     |\n",
      "|    policy_loss        | -0.0316  |\n",
      "|    value_loss         | 0.121    |\n",
      "------------------------------------\n",
      "--------------------\n",
      "Number of steps:  770.0\n",
      "Average reward:  -0.05\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  780.0\n",
      "Average reward:  0.0\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  790.0\n",
      "Average reward:  -0.05\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  800.0\n",
      "Average reward:  -0.2\n",
      "--------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 464      |\n",
      "|    iterations         | 2600     |\n",
      "|    time_elapsed       | 27       |\n",
      "|    total_timesteps    | 13000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0226  |\n",
      "|    explained_variance | -0.768   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2599     |\n",
      "|    policy_loss        | 6.83e-06 |\n",
      "|    value_loss         | 1.03e-05 |\n",
      "------------------------------------\n",
      "--------------------\n",
      "Number of steps:  810.0\n",
      "Average reward:  0.0\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  820.0\n",
      "Average reward:  0.25\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  830.0\n",
      "Average reward:  0.4\n",
      "--------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 464      |\n",
      "|    iterations         | 2700     |\n",
      "|    time_elapsed       | 29       |\n",
      "|    total_timesteps    | 13500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.237   |\n",
      "|    explained_variance | 0.00916  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2699     |\n",
      "|    policy_loss        | 0.327    |\n",
      "|    value_loss         | 0.579    |\n",
      "------------------------------------\n",
      "--------------------\n",
      "Number of steps:  840.0\n",
      "Average reward:  -0.5\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  850.0\n",
      "Average reward:  0.55\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  860.0\n",
      "Average reward:  0.55\n",
      "--------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 463       |\n",
      "|    iterations         | 2800      |\n",
      "|    time_elapsed       | 30        |\n",
      "|    total_timesteps    | 14000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.0167   |\n",
      "|    explained_variance | -3.91     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2799      |\n",
      "|    policy_loss        | -1.41e-05 |\n",
      "|    value_loss         | 6e-05     |\n",
      "-------------------------------------\n",
      "--------------------\n",
      "Number of steps:  870.0\n",
      "Average reward:  0.55\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  880.0\n",
      "Average reward:  0.55\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  890.0\n",
      "Average reward:  0.55\n",
      "--------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 459      |\n",
      "|    iterations         | 2900     |\n",
      "|    time_elapsed       | 31       |\n",
      "|    total_timesteps    | 14500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00636 |\n",
      "|    explained_variance | -4.74    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2899     |\n",
      "|    policy_loss        | -1.9e-05 |\n",
      "|    value_loss         | 0.0012   |\n",
      "------------------------------------\n",
      "--------------------\n",
      "Number of steps:  900.0\n",
      "Average reward:  0.7\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  910.0\n",
      "Average reward:  0.25\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  920.0\n",
      "Average reward:  0.7\n",
      "--------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 459       |\n",
      "|    iterations         | 3000      |\n",
      "|    time_elapsed       | 32        |\n",
      "|    total_timesteps    | 15000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.00169  |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2999      |\n",
      "|    policy_loss        | -3.66e-06 |\n",
      "|    value_loss         | 0.000533  |\n",
      "-------------------------------------\n",
      "--------------------\n",
      "Number of steps:  930.0\n",
      "Average reward:  0.4\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  940.0\n",
      "Average reward:  0.7\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  950.0\n",
      "Average reward:  0.25\n",
      "--------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 459      |\n",
      "|    iterations         | 3100     |\n",
      "|    time_elapsed       | 33       |\n",
      "|    total_timesteps    | 15500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00112 |\n",
      "|    explained_variance | -1.52    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3099     |\n",
      "|    policy_loss        | 3.21e-06 |\n",
      "|    value_loss         | 0.00103  |\n",
      "------------------------------------\n",
      "--------------------\n",
      "Number of steps:  960.0\n",
      "Average reward:  0.25\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  970.0\n",
      "Average reward:  -0.2\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  980.0\n",
      "Average reward:  -0.05\n",
      "--------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 458       |\n",
      "|    iterations         | 3200      |\n",
      "|    time_elapsed       | 34        |\n",
      "|    total_timesteps    | 16000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000596 |\n",
      "|    explained_variance | 0.495     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3199      |\n",
      "|    policy_loss        | 1.08e-07  |\n",
      "|    value_loss         | 4.41e-06  |\n",
      "-------------------------------------\n",
      "--------------------\n",
      "Number of steps:  990.0\n",
      "Average reward:  -0.2\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  1000.0\n",
      "Average reward:  0.85\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  1010.0\n",
      "Average reward:  0.55\n",
      "--------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 457      |\n",
      "|    iterations         | 3300     |\n",
      "|    time_elapsed       | 36       |\n",
      "|    total_timesteps    | 16500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.011   |\n",
      "|    explained_variance | -0.0134  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3299     |\n",
      "|    policy_loss        | 0.0019   |\n",
      "|    value_loss         | 0.566    |\n",
      "------------------------------------\n",
      "--------------------\n",
      "Number of steps:  1020.0\n",
      "Average reward:  0.55\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  1030.0\n",
      "Average reward:  -0.2\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  1040.0\n",
      "Average reward:  -0.05\n",
      "--------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 457       |\n",
      "|    iterations         | 3400      |\n",
      "|    time_elapsed       | 37        |\n",
      "|    total_timesteps    | 17000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000515 |\n",
      "|    explained_variance | -7.17     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3399      |\n",
      "|    policy_loss        | -7.15e-07 |\n",
      "|    value_loss         | 0.000398  |\n",
      "-------------------------------------\n",
      "--------------------\n",
      "Number of steps:  1050.0\n",
      "Average reward:  0.1\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  1060.0\n",
      "Average reward:  0.4\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  1070.0\n",
      "Average reward:  -0.05\n",
      "--------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 457       |\n",
      "|    iterations         | 3500      |\n",
      "|    time_elapsed       | 38        |\n",
      "|    total_timesteps    | 17500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000293 |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3499      |\n",
      "|    policy_loss        | -1.32e-07 |\n",
      "|    value_loss         | 3.34e-05  |\n",
      "-------------------------------------\n",
      "--------------------\n",
      "Number of steps:  1080.0\n",
      "Average reward:  -0.2\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  1090.0\n",
      "Average reward:  -0.05\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  1100.0\n",
      "Average reward:  -0.2\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  1110.0\n",
      "Average reward:  0.25\n",
      "--------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 454       |\n",
      "|    iterations         | 3600      |\n",
      "|    time_elapsed       | 39        |\n",
      "|    total_timesteps    | 18000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000436 |\n",
      "|    explained_variance | -18.6     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3599      |\n",
      "|    policy_loss        | 6.9e-08   |\n",
      "|    value_loss         | 3.42e-06  |\n",
      "-------------------------------------\n",
      "--------------------\n",
      "Number of steps:  1120.0\n",
      "Average reward:  0.1\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  1130.0\n",
      "Average reward:  -0.05\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  1140.0\n",
      "Average reward:  0.25\n",
      "--------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 452      |\n",
      "|    iterations         | 3700     |\n",
      "|    time_elapsed       | 40       |\n",
      "|    total_timesteps    | 18500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00861 |\n",
      "|    explained_variance | 0.0106   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3699     |\n",
      "|    policy_loss        | 0.00139  |\n",
      "|    value_loss         | 0.761    |\n",
      "------------------------------------\n",
      "--------------------\n",
      "Number of steps:  1150.0\n",
      "Average reward:  0.7\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  1160.0\n",
      "Average reward:  0.25\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  1170.0\n",
      "Average reward:  0.1\n",
      "--------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 452       |\n",
      "|    iterations         | 3800      |\n",
      "|    time_elapsed       | 42        |\n",
      "|    total_timesteps    | 19000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000361 |\n",
      "|    explained_variance | -0.626    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3799      |\n",
      "|    policy_loss        | -1.6e-07  |\n",
      "|    value_loss         | 4.31e-05  |\n",
      "-------------------------------------\n",
      "--------------------\n",
      "Number of steps:  1180.0\n",
      "Average reward:  0.7\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  1190.0\n",
      "Average reward:  0.25\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  1200.0\n",
      "Average reward:  0.1\n",
      "--------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 450       |\n",
      "|    iterations         | 3900      |\n",
      "|    time_elapsed       | 43        |\n",
      "|    total_timesteps    | 19500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000105 |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3899      |\n",
      "|    policy_loss        | -1.72e-08 |\n",
      "|    value_loss         | 5.46e-06  |\n",
      "-------------------------------------\n",
      "--------------------\n",
      "Number of steps:  1210.0\n",
      "Average reward:  -0.35\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  1220.0\n",
      "Average reward:  0.4\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  1230.0\n",
      "Average reward:  0.25\n",
      "--------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 450       |\n",
      "|    iterations         | 4000      |\n",
      "|    time_elapsed       | 44        |\n",
      "|    total_timesteps    | 20000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000159 |\n",
      "|    explained_variance | -4.32     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3999      |\n",
      "|    policy_loss        | 1.47e-07  |\n",
      "|    value_loss         | 0.000186  |\n",
      "-------------------------------------\n",
      "--------------------\n",
      "Number of steps:  1240.0\n",
      "Average reward:  0.85\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  1250.0\n",
      "Average reward:  -0.2\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  1260.0\n",
      "Average reward:  0.1\n",
      "--------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 449      |\n",
      "|    iterations         | 4100     |\n",
      "|    time_elapsed       | 45       |\n",
      "|    total_timesteps    | 20500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00104 |\n",
      "|    explained_variance | -43      |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4099     |\n",
      "|    policy_loss        | 9.22e-05 |\n",
      "|    value_loss         | 0.882    |\n",
      "------------------------------------\n",
      "--------------------\n",
      "Number of steps:  1270.0\n",
      "Average reward:  0.25\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  1280.0\n",
      "Average reward:  0.7\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  1290.0\n",
      "Average reward:  0.25\n",
      "--------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 449       |\n",
      "|    iterations         | 4200      |\n",
      "|    time_elapsed       | 46        |\n",
      "|    total_timesteps    | 21000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000915 |\n",
      "|    explained_variance | 0.211     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 4199      |\n",
      "|    policy_loss        | -4.7e-05  |\n",
      "|    value_loss         | 0.0473    |\n",
      "-------------------------------------\n",
      "--------------------\n",
      "Number of steps:  1300.0\n",
      "Average reward:  0.25\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  1310.0\n",
      "Average reward:  0.1\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  1320.0\n",
      "Average reward:  -0.5\n",
      "--------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 449      |\n",
      "|    iterations         | 4300     |\n",
      "|    time_elapsed       | 47       |\n",
      "|    total_timesteps    | 21500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00021 |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4299     |\n",
      "|    policy_loss        | 4.09e-08 |\n",
      "|    value_loss         | 6.55e-06 |\n",
      "------------------------------------\n",
      "--------------------\n",
      "Number of steps:  1330.0\n",
      "Average reward:  -0.05\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  1340.0\n",
      "Average reward:  0.4\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  1350.0\n",
      "Average reward:  -0.35\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  1360.0\n",
      "Average reward:  -0.05\n",
      "--------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 449       |\n",
      "|    iterations         | 4400      |\n",
      "|    time_elapsed       | 48        |\n",
      "|    total_timesteps    | 22000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000126 |\n",
      "|    explained_variance | -10.1     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 4399      |\n",
      "|    policy_loss        | -7.24e-08 |\n",
      "|    value_loss         | 0.000119  |\n",
      "-------------------------------------\n",
      "--------------------\n",
      "Number of steps:  1370.0\n",
      "Average reward:  0.55\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  1380.0\n",
      "Average reward:  0.1\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  1390.0\n",
      "Average reward:  -0.2\n",
      "--------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 446       |\n",
      "|    iterations         | 4500      |\n",
      "|    time_elapsed       | 50        |\n",
      "|    total_timesteps    | 22500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.00196  |\n",
      "|    explained_variance | -40.5     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 4499      |\n",
      "|    policy_loss        | -0.000151 |\n",
      "|    value_loss         | 0.264     |\n",
      "-------------------------------------\n",
      "--------------------\n",
      "Number of steps:  1400.0\n",
      "Average reward:  -0.2\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  1410.0\n",
      "Average reward:  0.55\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  1420.0\n",
      "Average reward:  0.4\n",
      "--------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 447       |\n",
      "|    iterations         | 4600      |\n",
      "|    time_elapsed       | 51        |\n",
      "|    total_timesteps    | 23000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.00156  |\n",
      "|    explained_variance | 0.105     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 4599      |\n",
      "|    policy_loss        | -8.77e-05 |\n",
      "|    value_loss         | 0.0464    |\n",
      "-------------------------------------\n",
      "--------------------\n",
      "Number of steps:  1430.0\n",
      "Average reward:  -0.35\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  1440.0\n",
      "Average reward:  0.25\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  1450.0\n",
      "Average reward:  0.55\n",
      "--------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 447       |\n",
      "|    iterations         | 4700      |\n",
      "|    time_elapsed       | 52        |\n",
      "|    total_timesteps    | 23500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000212 |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 4699      |\n",
      "|    policy_loss        | -1.41e-07 |\n",
      "|    value_loss         | 7.77e-05  |\n",
      "-------------------------------------\n",
      "--------------------\n",
      "Number of steps:  1460.0\n",
      "Average reward:  1.0\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  1470.0\n",
      "Average reward:  0.1\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  1480.0\n",
      "Average reward:  0.7\n",
      "--------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 447       |\n",
      "|    iterations         | 4800      |\n",
      "|    time_elapsed       | 53        |\n",
      "|    total_timesteps    | 24000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000202 |\n",
      "|    explained_variance | -0.492    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 4799      |\n",
      "|    policy_loss        | 1.74e-07  |\n",
      "|    value_loss         | 0.000193  |\n",
      "-------------------------------------\n",
      "--------------------\n",
      "Number of steps:  1490.0\n",
      "Average reward:  0.25\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  1500.0\n",
      "Average reward:  0.25\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  1510.0\n",
      "Average reward:  -0.05\n",
      "--------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 444       |\n",
      "|    iterations         | 4900      |\n",
      "|    time_elapsed       | 55        |\n",
      "|    total_timesteps    | 24500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000195 |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 4899      |\n",
      "|    policy_loss        | 3.6e-07   |\n",
      "|    value_loss         | 0.000507  |\n",
      "-------------------------------------\n",
      "--------------------\n",
      "Number of steps:  1520.0\n",
      "Average reward:  -0.05\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  1530.0\n",
      "Average reward:  0.7\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  1540.0\n",
      "Average reward:  0.55\n",
      "--------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 444       |\n",
      "|    iterations         | 5000      |\n",
      "|    time_elapsed       | 56        |\n",
      "|    total_timesteps    | 25000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.00279  |\n",
      "|    explained_variance | -0.286    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 4999      |\n",
      "|    policy_loss        | -0.000231 |\n",
      "|    value_loss         | 0.133     |\n",
      "-------------------------------------\n",
      "--------------------\n",
      "Number of steps:  1550.0\n",
      "Average reward:  -0.5\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  1560.0\n",
      "Average reward:  0.4\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  1570.0\n",
      "Average reward:  0.85\n",
      "--------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 444       |\n",
      "|    iterations         | 5100      |\n",
      "|    time_elapsed       | 57        |\n",
      "|    total_timesteps    | 25500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000305 |\n",
      "|    explained_variance | -4.75     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 5099      |\n",
      "|    policy_loss        | -3.14e-07 |\n",
      "|    value_loss         | 0.000338  |\n",
      "-------------------------------------\n",
      "--------------------\n",
      "Number of steps:  1580.0\n",
      "Average reward:  -0.05\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  1590.0\n",
      "Average reward:  0.85\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  1600.0\n",
      "Average reward:  0.7\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  1610.0\n",
      "Average reward:  1.0\n",
      "--------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 444       |\n",
      "|    iterations         | 5200      |\n",
      "|    time_elapsed       | 58        |\n",
      "|    total_timesteps    | 26000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000227 |\n",
      "|    explained_variance | -0.865    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 5199      |\n",
      "|    policy_loss        | 5.32e-07  |\n",
      "|    value_loss         | 0.000963  |\n",
      "-------------------------------------\n",
      "--------------------\n",
      "Number of steps:  1620.0\n",
      "Average reward:  -0.2\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  1630.0\n",
      "Average reward:  1.0\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  1640.0\n",
      "Average reward:  0.85\n",
      "--------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 442       |\n",
      "|    iterations         | 5300      |\n",
      "|    time_elapsed       | 59        |\n",
      "|    total_timesteps    | 26500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000114 |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 5299      |\n",
      "|    policy_loss        | -1.27e-06 |\n",
      "|    value_loss         | 0.0198    |\n",
      "-------------------------------------\n",
      "--------------------\n",
      "Number of steps:  1650.0\n",
      "Average reward:  0.55\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  1660.0\n",
      "Average reward:  0.7\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  1670.0\n",
      "Average reward:  -0.5\n",
      "--------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 442       |\n",
      "|    iterations         | 5400      |\n",
      "|    time_elapsed       | 61        |\n",
      "|    total_timesteps    | 27000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000983 |\n",
      "|    explained_variance | -0.726    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 5399      |\n",
      "|    policy_loss        | -8.75e-05 |\n",
      "|    value_loss         | 0.201     |\n",
      "-------------------------------------\n",
      "--------------------\n",
      "Number of steps:  1680.0\n",
      "Average reward:  0.1\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  1690.0\n",
      "Average reward:  0.85\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  1700.0\n",
      "Average reward:  -0.05\n",
      "--------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 441       |\n",
      "|    iterations         | 5500      |\n",
      "|    time_elapsed       | 62        |\n",
      "|    total_timesteps    | 27500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000124 |\n",
      "|    explained_variance | -7.27     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 5499      |\n",
      "|    policy_loss        | -2.05e-07 |\n",
      "|    value_loss         | 0.000803  |\n",
      "-------------------------------------\n",
      "--------------------\n",
      "Number of steps:  1710.0\n",
      "Average reward:  0.25\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  1720.0\n",
      "Average reward:  0.25\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  1730.0\n",
      "Average reward:  0.85\n",
      "--------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 442       |\n",
      "|    iterations         | 5600      |\n",
      "|    time_elapsed       | 63        |\n",
      "|    total_timesteps    | 28000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000177 |\n",
      "|    explained_variance | -0.963    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 5599      |\n",
      "|    policy_loss        | 5.28e-07  |\n",
      "|    value_loss         | 0.00163   |\n",
      "-------------------------------------\n",
      "--------------------\n",
      "Number of steps:  1740.0\n",
      "Average reward:  0.55\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  1750.0\n",
      "Average reward:  -0.5\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  1760.0\n",
      "Average reward:  -0.2\n",
      "--------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 441      |\n",
      "|    iterations         | 5700     |\n",
      "|    time_elapsed       | 64       |\n",
      "|    total_timesteps    | 28500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00017 |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 5699     |\n",
      "|    policy_loss        | 7.16e-06 |\n",
      "|    value_loss         | 0.268    |\n",
      "------------------------------------\n",
      "--------------------\n",
      "Number of steps:  1770.0\n",
      "Average reward:  -0.35\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  1780.0\n",
      "Average reward:  0.25\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  1790.0\n",
      "Average reward:  0.1\n",
      "--------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 441       |\n",
      "|    iterations         | 5800      |\n",
      "|    time_elapsed       | 65        |\n",
      "|    total_timesteps    | 29000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.00518  |\n",
      "|    explained_variance | -2.65     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 5799      |\n",
      "|    policy_loss        | -8.12e-06 |\n",
      "|    value_loss         | 0.000303  |\n",
      "-------------------------------------\n",
      "--------------------\n",
      "Number of steps:  1800.0\n",
      "Average reward:  0.55\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  1810.0\n",
      "Average reward:  0.2\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  1820.0\n",
      "Average reward:  0.25\n",
      "--------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 441      |\n",
      "|    iterations         | 5900     |\n",
      "|    time_elapsed       | 66       |\n",
      "|    total_timesteps    | 29500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.141   |\n",
      "|    explained_variance | -3.37    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 5899     |\n",
      "|    policy_loss        | 0.0861   |\n",
      "|    value_loss         | 0.89     |\n",
      "------------------------------------\n",
      "--------------------\n",
      "Number of steps:  1830.0\n",
      "Average reward:  -0.05\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  1840.0\n",
      "Average reward:  0.85\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  1850.0\n",
      "Average reward:  0.25\n",
      "--------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 441      |\n",
      "|    iterations         | 6000     |\n",
      "|    time_elapsed       | 67       |\n",
      "|    total_timesteps    | 30000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00568 |\n",
      "|    explained_variance | -2.18    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 5999     |\n",
      "|    policy_loss        | 6.4e-06  |\n",
      "|    value_loss         | 0.00029  |\n",
      "------------------------------------\n",
      "--------------------\n",
      "Number of steps:  1860.0\n",
      "Average reward:  0.25\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  1870.0\n",
      "Average reward:  0.55\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  1880.0\n",
      "Average reward:  -0.05\n",
      "--------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 442       |\n",
      "|    iterations         | 6100      |\n",
      "|    time_elapsed       | 68        |\n",
      "|    total_timesteps    | 30500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.00228  |\n",
      "|    explained_variance | -0.582    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 6099      |\n",
      "|    policy_loss        | -2.97e-06 |\n",
      "|    value_loss         | 0.000373  |\n",
      "-------------------------------------\n",
      "--------------------\n",
      "Number of steps:  1890.0\n",
      "Average reward:  0.85\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  1900.0\n",
      "Average reward:  0.85\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  1910.0\n",
      "Average reward:  0.4\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  1920.0\n",
      "Average reward:  0.7\n",
      "--------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 442      |\n",
      "|    iterations         | 6200     |\n",
      "|    time_elapsed       | 70       |\n",
      "|    total_timesteps    | 31000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0257  |\n",
      "|    explained_variance | -0.642   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 6199     |\n",
      "|    policy_loss        | -0.00286 |\n",
      "|    value_loss         | 0.279    |\n",
      "------------------------------------\n",
      "--------------------\n",
      "Number of steps:  1930.0\n",
      "Average reward:  0.25\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  1940.0\n",
      "Average reward:  0.4\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  1950.0\n",
      "Average reward:  0.55\n",
      "--------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 440      |\n",
      "|    iterations         | 6300     |\n",
      "|    time_elapsed       | 71       |\n",
      "|    total_timesteps    | 31500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0133  |\n",
      "|    explained_variance | -0.339   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 6299     |\n",
      "|    policy_loss        | -0.00189 |\n",
      "|    value_loss         | 0.199    |\n",
      "------------------------------------\n",
      "--------------------\n",
      "Number of steps:  1960.0\n",
      "Average reward:  -0.5\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  1970.0\n",
      "Average reward:  0.4\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  1980.0\n",
      "Average reward:  0.1\n",
      "--------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 440       |\n",
      "|    iterations         | 6400      |\n",
      "|    time_elapsed       | 72        |\n",
      "|    total_timesteps    | 32000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000223 |\n",
      "|    explained_variance | -7.63     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 6399      |\n",
      "|    policy_loss        | -5.73e-07 |\n",
      "|    value_loss         | 0.00161   |\n",
      "-------------------------------------\n",
      "--------------------\n",
      "Number of steps:  1990.0\n",
      "Average reward:  0.55\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  2000.0\n",
      "Average reward:  0.7\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  2010.0\n",
      "Average reward:  0.25\n",
      "--------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 438       |\n",
      "|    iterations         | 6500      |\n",
      "|    time_elapsed       | 74        |\n",
      "|    total_timesteps    | 32500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000201 |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 6499      |\n",
      "|    policy_loss        | 9.15e-07  |\n",
      "|    value_loss         | 0.00312   |\n",
      "-------------------------------------\n",
      "--------------------\n",
      "Number of steps:  2020.0\n",
      "Average reward:  0.25\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  2030.0\n",
      "Average reward:  0.7\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  2040.0\n",
      "Average reward:  -0.05\n",
      "--------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 438       |\n",
      "|    iterations         | 6600      |\n",
      "|    time_elapsed       | 75        |\n",
      "|    total_timesteps    | 33000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.75e-05 |\n",
      "|    explained_variance | -2.44     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 6599      |\n",
      "|    policy_loss        | 7.58e-09  |\n",
      "|    value_loss         | 0.000777  |\n",
      "-------------------------------------\n",
      "--------------------\n",
      "Number of steps:  2050.0\n",
      "Average reward:  -0.05\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  2060.0\n",
      "Average reward:  0.7\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  2070.0\n",
      "Average reward:  1.0\n",
      "--------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 438      |\n",
      "|    iterations         | 6700     |\n",
      "|    time_elapsed       | 76       |\n",
      "|    total_timesteps    | 33500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00372 |\n",
      "|    explained_variance | -0.331   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 6699     |\n",
      "|    policy_loss        | -0.00039 |\n",
      "|    value_loss         | 0.284    |\n",
      "------------------------------------\n",
      "--------------------\n",
      "Number of steps:  2080.0\n",
      "Average reward:  -0.2\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  2090.0\n",
      "Average reward:  0.7\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  2100.0\n",
      "Average reward:  -0.5\n",
      "--------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 438       |\n",
      "|    iterations         | 6800      |\n",
      "|    time_elapsed       | 77        |\n",
      "|    total_timesteps    | 34000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.46e-05 |\n",
      "|    explained_variance | -14.7     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 6799      |\n",
      "|    policy_loss        | -3.9e-07  |\n",
      "|    value_loss         | 0.00954   |\n",
      "-------------------------------------\n",
      "--------------------\n",
      "Number of steps:  2110.0\n",
      "Average reward:  0.7\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  2120.0\n",
      "Average reward:  0.4\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  2130.0\n",
      "Average reward:  0.25\n",
      "--------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 439       |\n",
      "|    iterations         | 6900      |\n",
      "|    time_elapsed       | 78        |\n",
      "|    total_timesteps    | 34500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -9.3e-05  |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 6899      |\n",
      "|    policy_loss        | -2.31e-07 |\n",
      "|    value_loss         | 0.00127   |\n",
      "-------------------------------------\n",
      "--------------------\n",
      "Number of steps:  2140.0\n",
      "Average reward:  0.55\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  2150.0\n",
      "Average reward:  1.0\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  2160.0\n",
      "Average reward:  1.0\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  2170.0\n",
      "Average reward:  0.1\n",
      "--------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 439       |\n",
      "|    iterations         | 7000      |\n",
      "|    time_elapsed       | 79        |\n",
      "|    total_timesteps    | 35000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.78e-05 |\n",
      "|    explained_variance | -2.99     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 6999      |\n",
      "|    policy_loss        | 4.97e-08  |\n",
      "|    value_loss         | 0.00186   |\n",
      "-------------------------------------\n",
      "--------------------\n",
      "Number of steps:  2180.0\n",
      "Average reward:  0.85\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  2190.0\n",
      "Average reward:  -0.05\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  2200.0\n",
      "Average reward:  0.25\n",
      "--------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 438       |\n",
      "|    iterations         | 7100      |\n",
      "|    time_elapsed       | 81        |\n",
      "|    total_timesteps    | 35500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.00192  |\n",
      "|    explained_variance | -1.21     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 7099      |\n",
      "|    policy_loss        | -0.000245 |\n",
      "|    value_loss         | 0.372     |\n",
      "-------------------------------------\n",
      "--------------------\n",
      "Number of steps:  2210.0\n",
      "Average reward:  0.25\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  2220.0\n",
      "Average reward:  0.7\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  2230.0\n",
      "Average reward:  -0.05\n",
      "--------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 438       |\n",
      "|    iterations         | 7200      |\n",
      "|    time_elapsed       | 82        |\n",
      "|    total_timesteps    | 36000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.36e-05 |\n",
      "|    explained_variance | -4.92     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 7199      |\n",
      "|    policy_loss        | -2.11e-07 |\n",
      "|    value_loss         | 0.00487   |\n",
      "-------------------------------------\n",
      "--------------------\n",
      "Number of steps:  2240.0\n",
      "Average reward:  0.85\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  2250.0\n",
      "Average reward:  0.25\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  2260.0\n",
      "Average reward:  0.55\n",
      "--------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 438       |\n",
      "|    iterations         | 7300      |\n",
      "|    time_elapsed       | 83        |\n",
      "|    total_timesteps    | 36500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.99e-05 |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 7299      |\n",
      "|    policy_loss        | -1.78e-07 |\n",
      "|    value_loss         | 0.00266   |\n",
      "-------------------------------------\n",
      "--------------------\n",
      "Number of steps:  2270.0\n",
      "Average reward:  1.0\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  2280.0\n",
      "Average reward:  -0.2\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  2290.0\n",
      "Average reward:  0.25\n",
      "--------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 439      |\n",
      "|    iterations         | 7400     |\n",
      "|    time_elapsed       | 84       |\n",
      "|    total_timesteps    | 37000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.5e-05 |\n",
      "|    explained_variance | -4.45    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 7399     |\n",
      "|    policy_loss        | 5.29e-08 |\n",
      "|    value_loss         | 0.00106  |\n",
      "------------------------------------\n",
      "--------------------\n",
      "Number of steps:  2300.0\n",
      "Average reward:  -0.35\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  2310.0\n",
      "Average reward:  -0.05\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  2320.0\n",
      "Average reward:  0.55\n",
      "--------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 439       |\n",
      "|    iterations         | 7500      |\n",
      "|    time_elapsed       | 85        |\n",
      "|    total_timesteps    | 37500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000183 |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 7499      |\n",
      "|    policy_loss        | 3.79e-06  |\n",
      "|    value_loss         | 0.0621    |\n",
      "-------------------------------------\n",
      "--------------------\n",
      "Number of steps:  2330.0\n",
      "Average reward:  0.25\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  2340.0\n",
      "Average reward:  0.55\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  2350.0\n",
      "Average reward:  0.7\n",
      "--------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 439      |\n",
      "|    iterations         | 7600     |\n",
      "|    time_elapsed       | 86       |\n",
      "|    total_timesteps    | 38000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.014   |\n",
      "|    explained_variance | 0.096    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 7599     |\n",
      "|    policy_loss        | 0.00211  |\n",
      "|    value_loss         | 0.47     |\n",
      "------------------------------------\n",
      "--------------------\n",
      "Number of steps:  2360.0\n",
      "Average reward:  0.55\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  2370.0\n",
      "Average reward:  -0.35\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  2380.0\n",
      "Average reward:  -0.2\n",
      "--------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 439       |\n",
      "|    iterations         | 7700      |\n",
      "|    time_elapsed       | 87        |\n",
      "|    total_timesteps    | 38500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000196 |\n",
      "|    explained_variance | -14.3     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 7699      |\n",
      "|    policy_loss        | -5.82e-07 |\n",
      "|    value_loss         | 0.0023    |\n",
      "-------------------------------------\n",
      "--------------------\n",
      "Number of steps:  2390.0\n",
      "Average reward:  0.25\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  2400.0\n",
      "Average reward:  0.25\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  2410.0\n",
      "Average reward:  -0.05\n",
      "--------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 439       |\n",
      "|    iterations         | 7800      |\n",
      "|    time_elapsed       | 88        |\n",
      "|    total_timesteps    | 39000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000551 |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 7799      |\n",
      "|    policy_loss        | -1.15e-06 |\n",
      "|    value_loss         | 0.000627  |\n",
      "-------------------------------------\n",
      "--------------------\n",
      "Number of steps:  2420.0\n",
      "Average reward:  0.7\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  2430.0\n",
      "Average reward:  0.85\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  2440.0\n",
      "Average reward:  0.85\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  2450.0\n",
      "Average reward:  -0.2\n",
      "--------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 438       |\n",
      "|    iterations         | 7900      |\n",
      "|    time_elapsed       | 90        |\n",
      "|    total_timesteps    | 39500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.87e-05 |\n",
      "|    explained_variance | -0.869    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 7899      |\n",
      "|    policy_loss        | 1.3e-07   |\n",
      "|    value_loss         | 0.000738  |\n",
      "-------------------------------------\n",
      "--------------------\n",
      "Number of steps:  2460.0\n",
      "Average reward:  0.25\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  2470.0\n",
      "Average reward:  1.0\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  2480.0\n",
      "Average reward:  -0.2\n",
      "--------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 438       |\n",
      "|    iterations         | 8000      |\n",
      "|    time_elapsed       | 91        |\n",
      "|    total_timesteps    | 40000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.23e-05 |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 7999      |\n",
      "|    policy_loss        | 1.84e-06  |\n",
      "|    value_loss         | 0.124     |\n",
      "-------------------------------------\n",
      "--------------------\n",
      "Number of steps:  2490.0\n",
      "Average reward:  0.1\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  2500.0\n",
      "Average reward:  0.55\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  2510.0\n",
      "Average reward:  0.7\n",
      "--------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 439      |\n",
      "|    iterations         | 8100     |\n",
      "|    time_elapsed       | 92       |\n",
      "|    total_timesteps    | 40500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00946 |\n",
      "|    explained_variance | -0.554   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 8099     |\n",
      "|    policy_loss        | -0.00136 |\n",
      "|    value_loss         | 0.22     |\n",
      "------------------------------------\n",
      "--------------------\n",
      "Number of steps:  2520.0\n",
      "Average reward:  -0.35\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  2530.0\n",
      "Average reward:  1.0\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  2540.0\n",
      "Average reward:  0.25\n",
      "--------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 439       |\n",
      "|    iterations         | 8200      |\n",
      "|    time_elapsed       | 93        |\n",
      "|    total_timesteps    | 41000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.91e-05 |\n",
      "|    explained_variance | -4.24     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 8199      |\n",
      "|    policy_loss        | -2.11e-07 |\n",
      "|    value_loss         | 0.00265   |\n",
      "-------------------------------------\n",
      "--------------------\n",
      "Number of steps:  2550.0\n",
      "Average reward:  -0.2\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  2560.0\n",
      "Average reward:  0.4\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  2570.0\n",
      "Average reward:  0.25\n",
      "--------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 439      |\n",
      "|    iterations         | 8300     |\n",
      "|    time_elapsed       | 94       |\n",
      "|    total_timesteps    | 41500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -9.4e-05 |\n",
      "|    explained_variance | -2.25    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 8299     |\n",
      "|    policy_loss        | 2.71e-07 |\n",
      "|    value_loss         | 0.00182  |\n",
      "------------------------------------\n",
      "--------------------\n",
      "Number of steps:  2580.0\n",
      "Average reward:  0.7\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  2590.0\n",
      "Average reward:  0.55\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  2600.0\n",
      "Average reward:  -0.05\n",
      "--------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 439       |\n",
      "|    iterations         | 8400      |\n",
      "|    time_elapsed       | 95        |\n",
      "|    total_timesteps    | 42000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.16e-05 |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 8399      |\n",
      "|    policy_loss        | 6.02e-07  |\n",
      "|    value_loss         | 0.0253    |\n",
      "-------------------------------------\n",
      "--------------------\n",
      "Number of steps:  2610.0\n",
      "Average reward:  0.7\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  2620.0\n",
      "Average reward:  -0.2\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  2630.0\n",
      "Average reward:  0.7\n",
      "--------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 437      |\n",
      "|    iterations         | 8500     |\n",
      "|    time_elapsed       | 97       |\n",
      "|    total_timesteps    | 42500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0398  |\n",
      "|    explained_variance | -1       |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 8499     |\n",
      "|    policy_loss        | 0.00853  |\n",
      "|    value_loss         | 0.832    |\n",
      "------------------------------------\n",
      "--------------------\n",
      "Number of steps:  2640.0\n",
      "Average reward:  0.7\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  2650.0\n",
      "Average reward:  1.0\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  2660.0\n",
      "Average reward:  1.0\n",
      "--------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 437      |\n",
      "|    iterations         | 8600     |\n",
      "|    time_elapsed       | 98       |\n",
      "|    total_timesteps    | 43000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0157  |\n",
      "|    explained_variance | -1.22    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 8599     |\n",
      "|    policy_loss        | -0.00278 |\n",
      "|    value_loss         | 0.181    |\n",
      "------------------------------------\n",
      "--------------------\n",
      "Number of steps:  2670.0\n",
      "Average reward:  0.4\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  2680.0\n",
      "Average reward:  -0.35\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  2690.0\n",
      "Average reward:  0.1\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  2700.0\n",
      "Average reward:  0.1\n",
      "--------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 436       |\n",
      "|    iterations         | 8700      |\n",
      "|    time_elapsed       | 99        |\n",
      "|    total_timesteps    | 43500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000349 |\n",
      "|    explained_variance | -4.98     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 8699      |\n",
      "|    policy_loss        | -9.7e-07  |\n",
      "|    value_loss         | 0.00179   |\n",
      "-------------------------------------\n",
      "--------------------\n",
      "Number of steps:  2710.0\n",
      "Average reward:  -0.35\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  2720.0\n",
      "Average reward:  -0.35\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  2730.0\n",
      "Average reward:  -0.35\n",
      "--------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 436      |\n",
      "|    iterations         | 8800     |\n",
      "|    time_elapsed       | 100      |\n",
      "|    total_timesteps    | 44000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00157 |\n",
      "|    explained_variance | -5.91    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 8799     |\n",
      "|    policy_loss        | 6.22e-08 |\n",
      "|    value_loss         | 1.48e-05 |\n",
      "------------------------------------\n",
      "--------------------\n",
      "Number of steps:  2740.0\n",
      "Average reward:  0.6\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  2750.0\n",
      "Average reward:  -0.3\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  2760.0\n",
      "Average reward:  0.45\n",
      "--------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 436      |\n",
      "|    iterations         | 8900     |\n",
      "|    time_elapsed       | 101      |\n",
      "|    total_timesteps    | 44500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.138   |\n",
      "|    explained_variance | -20.9    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 8899     |\n",
      "|    policy_loss        | -0.00109 |\n",
      "|    value_loss         | 0.00769  |\n",
      "------------------------------------\n",
      "--------------------\n",
      "Number of steps:  2770.0\n",
      "Average reward:  0.75\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  2780.0\n",
      "Average reward:  -0.05\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  2790.0\n",
      "Average reward:  -0.2\n",
      "--------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 436       |\n",
      "|    iterations         | 9000      |\n",
      "|    time_elapsed       | 103       |\n",
      "|    total_timesteps    | 45000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000424 |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 8999      |\n",
      "|    policy_loss        | -4.11e-07 |\n",
      "|    value_loss         | 0.000145  |\n",
      "-------------------------------------\n",
      "--------------------\n",
      "Number of steps:  2800.0\n",
      "Average reward:  0.55\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  2810.0\n",
      "Average reward:  0.4\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  2820.0\n",
      "Average reward:  0.55\n",
      "--------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 436       |\n",
      "|    iterations         | 9100      |\n",
      "|    time_elapsed       | 104       |\n",
      "|    total_timesteps    | 45500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.24e-05 |\n",
      "|    explained_variance | 1.79e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 9099      |\n",
      "|    policy_loss        | -9.93e-08 |\n",
      "|    value_loss         | 0.000528  |\n",
      "-------------------------------------\n",
      "--------------------\n",
      "Number of steps:  2830.0\n",
      "Average reward:  -0.05\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  2840.0\n",
      "Average reward:  0.25\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  2850.0\n",
      "Average reward:  0.7\n",
      "--------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 437       |\n",
      "|    iterations         | 9200      |\n",
      "|    time_elapsed       | 105       |\n",
      "|    total_timesteps    | 46000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.76e-05 |\n",
      "|    explained_variance | -3.43     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 9199      |\n",
      "|    policy_loss        | 2.6e-08   |\n",
      "|    value_loss         | 0.000616  |\n",
      "-------------------------------------\n",
      "--------------------\n",
      "Number of steps:  2860.0\n",
      "Average reward:  0.55\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  2870.0\n",
      "Average reward:  -0.05\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  2880.0\n",
      "Average reward:  -0.5\n",
      "--------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 437      |\n",
      "|    iterations         | 9300     |\n",
      "|    time_elapsed       | 106      |\n",
      "|    total_timesteps    | 46500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00879 |\n",
      "|    explained_variance | -13.4    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 9299     |\n",
      "|    policy_loss        | 0.00116  |\n",
      "|    value_loss         | 0.859    |\n",
      "------------------------------------\n",
      "--------------------\n",
      "Number of steps:  2890.0\n",
      "Average reward:  1.0\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  2900.0\n",
      "Average reward:  1.0\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  2910.0\n",
      "Average reward:  1.0\n",
      "--------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 437       |\n",
      "|    iterations         | 9400      |\n",
      "|    time_elapsed       | 107       |\n",
      "|    total_timesteps    | 47000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.00519  |\n",
      "|    explained_variance | -0.636    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 9399      |\n",
      "|    policy_loss        | -0.000603 |\n",
      "|    value_loss         | 0.122     |\n",
      "-------------------------------------\n",
      "--------------------\n",
      "Number of steps:  2920.0\n",
      "Average reward:  -0.2\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  2930.0\n",
      "Average reward:  0.1\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  2940.0\n",
      "Average reward:  -0.5\n",
      "--------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 437       |\n",
      "|    iterations         | 9500      |\n",
      "|    time_elapsed       | 108       |\n",
      "|    total_timesteps    | 47500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.47e-05 |\n",
      "|    explained_variance | -4.83     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 9499      |\n",
      "|    policy_loss        | -3.86e-09 |\n",
      "|    value_loss         | 4.94e-05  |\n",
      "-------------------------------------\n",
      "--------------------\n",
      "Number of steps:  2950.0\n",
      "Average reward:  0.25\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  2960.0\n",
      "Average reward:  -0.2\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  2970.0\n",
      "Average reward:  -0.2\n",
      "--------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 436       |\n",
      "|    iterations         | 9600      |\n",
      "|    time_elapsed       | 109       |\n",
      "|    total_timesteps    | 48000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.21e-05 |\n",
      "|    explained_variance | -1.77     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 9599      |\n",
      "|    policy_loss        | 1.28e-09  |\n",
      "|    value_loss         | 2.73e-06  |\n",
      "-------------------------------------\n",
      "--------------------\n",
      "Number of steps:  2980.0\n",
      "Average reward:  0.4\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  2990.0\n",
      "Average reward:  -0.05\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  3000.0\n",
      "Average reward:  0.55\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  3010.0\n",
      "Average reward:  0.85\n",
      "--------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 436       |\n",
      "|    iterations         | 9700      |\n",
      "|    time_elapsed       | 111       |\n",
      "|    total_timesteps    | 48500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.1e-05  |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 9699      |\n",
      "|    policy_loss        | -1.45e-08 |\n",
      "|    value_loss         | 0.00104   |\n",
      "-------------------------------------\n",
      "--------------------\n",
      "Number of steps:  3020.0\n",
      "Average reward:  -0.35\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  3030.0\n",
      "Average reward:  0.4\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  3040.0\n",
      "Average reward:  0.25\n",
      "--------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 436      |\n",
      "|    iterations         | 9800     |\n",
      "|    time_elapsed       | 112      |\n",
      "|    total_timesteps    | 49000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00306 |\n",
      "|    explained_variance | -0.332   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 9799     |\n",
      "|    policy_loss        | -0.00029 |\n",
      "|    value_loss         | 0.15     |\n",
      "------------------------------------\n",
      "--------------------\n",
      "Number of steps:  3050.0\n",
      "Average reward:  -0.2\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  3060.0\n",
      "Average reward:  -0.05\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  3070.0\n",
      "Average reward:  -0.05\n",
      "--------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 436       |\n",
      "|    iterations         | 9900      |\n",
      "|    time_elapsed       | 113       |\n",
      "|    total_timesteps    | 49500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.14e-05 |\n",
      "|    explained_variance | 0.248     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 9899      |\n",
      "|    policy_loss        | -3e-09    |\n",
      "|    value_loss         | 6.41e-06  |\n",
      "-------------------------------------\n",
      "--------------------\n",
      "Number of steps:  3080.0\n",
      "Average reward:  0.1\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  3090.0\n",
      "Average reward:  -0.15\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  3100.0\n",
      "Average reward:  0.85\n",
      "--------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 436      |\n",
      "|    iterations         | 10000    |\n",
      "|    time_elapsed       | 114      |\n",
      "|    total_timesteps    | 50000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.1e-05 |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 9999     |\n",
      "|    policy_loss        | -2.9e-09 |\n",
      "|    value_loss         | 4.5e-05  |\n",
      "------------------------------------\n",
      "--------------------\n",
      "Number of steps:  3110.0\n",
      "Average reward:  0.25\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  3120.0\n",
      "Average reward:  1.0\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  3130.0\n",
      "Average reward:  -0.2\n",
      "--------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 436       |\n",
      "|    iterations         | 10100     |\n",
      "|    time_elapsed       | 115       |\n",
      "|    total_timesteps    | 50500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.16e-05 |\n",
      "|    explained_variance | -2.79     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 10099     |\n",
      "|    policy_loss        | 1.07e-08  |\n",
      "|    value_loss         | 0.00032   |\n",
      "-------------------------------------\n",
      "--------------------\n",
      "Number of steps:  3140.0\n",
      "Average reward:  1.0\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  3150.0\n",
      "Average reward:  0.25\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  3160.0\n",
      "Average reward:  0.55\n",
      "--------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 436      |\n",
      "|    iterations         | 10200    |\n",
      "|    time_elapsed       | 116      |\n",
      "|    total_timesteps    | 51000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0041  |\n",
      "|    explained_variance | 0.482    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 10199    |\n",
      "|    policy_loss        | 0.000563 |\n",
      "|    value_loss         | 0.887    |\n",
      "------------------------------------\n",
      "--------------------\n",
      "Number of steps:  3170.0\n",
      "Average reward:  0.25\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  3180.0\n",
      "Average reward:  1.0\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  3190.0\n",
      "Average reward:  0.1\n",
      "--------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 435       |\n",
      "|    iterations         | 10300     |\n",
      "|    time_elapsed       | 118       |\n",
      "|    total_timesteps    | 51500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.00359  |\n",
      "|    explained_variance | -0.489    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 10299     |\n",
      "|    policy_loss        | -0.000353 |\n",
      "|    value_loss         | 0.096     |\n",
      "-------------------------------------\n",
      "--------------------\n",
      "Number of steps:  3200.0\n",
      "Average reward:  0.1\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  3210.0\n",
      "Average reward:  0.7\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  3220.0\n",
      "Average reward:  0.85\n",
      "--------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 436       |\n",
      "|    iterations         | 10400     |\n",
      "|    time_elapsed       | 119       |\n",
      "|    total_timesteps    | 52000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.71e-06 |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 10399     |\n",
      "|    policy_loss        | -1.4e-08  |\n",
      "|    value_loss         | 0.00105   |\n",
      "-------------------------------------\n",
      "--------------------\n",
      "Number of steps:  3230.0\n",
      "Average reward:  -0.05\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  3240.0\n",
      "Average reward:  1.0\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  3250.0\n",
      "Average reward:  1.0\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  3260.0\n",
      "Average reward:  -0.2\n",
      "--------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 436       |\n",
      "|    iterations         | 10500     |\n",
      "|    time_elapsed       | 120       |\n",
      "|    total_timesteps    | 52500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -3.74e-06 |\n",
      "|    explained_variance | -5.59     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 10499     |\n",
      "|    policy_loss        | -0        |\n",
      "|    value_loss         | 0.00332   |\n",
      "-------------------------------------\n",
      "--------------------\n",
      "Number of steps:  3270.0\n",
      "Average reward:  0.55\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  3280.0\n",
      "Average reward:  0.25\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  3290.0\n",
      "Average reward:  -0.5\n",
      "--------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 435       |\n",
      "|    iterations         | 10600     |\n",
      "|    time_elapsed       | 121       |\n",
      "|    total_timesteps    | 53000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.00282  |\n",
      "|    explained_variance | -2.17e+08 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 10599     |\n",
      "|    policy_loss        | -0.000405 |\n",
      "|    value_loss         | 0.421     |\n",
      "-------------------------------------\n",
      "--------------------\n",
      "Number of steps:  3300.0\n",
      "Average reward:  0.55\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  3310.0\n",
      "Average reward:  -0.5\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  3320.0\n",
      "Average reward:  0.1\n",
      "--------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 435      |\n",
      "|    iterations         | 10700    |\n",
      "|    time_elapsed       | 122      |\n",
      "|    total_timesteps    | 53500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.15    |\n",
      "|    explained_variance | -1.93    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 10699    |\n",
      "|    policy_loss        | -0.95    |\n",
      "|    value_loss         | 0.509    |\n",
      "------------------------------------\n",
      "--------------------\n",
      "Number of steps:  3330.0\n",
      "Average reward:  0.25\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  3340.0\n",
      "Average reward:  -0.35\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  3350.0\n",
      "Average reward:  0.4\n",
      "--------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 435      |\n",
      "|    iterations         | 10800    |\n",
      "|    time_elapsed       | 123      |\n",
      "|    total_timesteps    | 54000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0578  |\n",
      "|    explained_variance | -1.37    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 10799    |\n",
      "|    policy_loss        | -0.0137  |\n",
      "|    value_loss         | 0.122    |\n",
      "------------------------------------\n",
      "--------------------\n",
      "Number of steps:  3360.0\n",
      "Average reward:  0.1\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  3370.0\n",
      "Average reward:  -0.2\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  3380.0\n",
      "Average reward:  0.1\n",
      "--------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 435      |\n",
      "|    iterations         | 10900    |\n",
      "|    time_elapsed       | 125      |\n",
      "|    total_timesteps    | 54500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.094   |\n",
      "|    explained_variance | 0.505    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 10899    |\n",
      "|    policy_loss        | 0.0379   |\n",
      "|    value_loss         | 0.928    |\n",
      "------------------------------------\n",
      "--------------------\n",
      "Number of steps:  3390.0\n",
      "Average reward:  0.7\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  3400.0\n",
      "Average reward:  -0.05\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  3410.0\n",
      "Average reward:  0.2\n",
      "--------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 433       |\n",
      "|    iterations         | 11000     |\n",
      "|    time_elapsed       | 126       |\n",
      "|    total_timesteps    | 55000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000187 |\n",
      "|    explained_variance | -8.32     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 10999     |\n",
      "|    policy_loss        | -3.98e-07 |\n",
      "|    value_loss         | 0.000907  |\n",
      "-------------------------------------\n",
      "--------------------\n",
      "Number of steps:  3420.0\n",
      "Average reward:  0.25\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  3430.0\n",
      "Average reward:  0.4\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  3440.0\n",
      "Average reward:  0.85\n",
      "--------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 433      |\n",
      "|    iterations         | 11100    |\n",
      "|    time_elapsed       | 128      |\n",
      "|    total_timesteps    | 55500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.123   |\n",
      "|    explained_variance | -3.75    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 11099    |\n",
      "|    policy_loss        | -0.0122  |\n",
      "|    value_loss         | 0.00254  |\n",
      "------------------------------------\n",
      "--------------------\n",
      "Number of steps:  3450.0\n",
      "Average reward:  0.55\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  3460.0\n",
      "Average reward:  0.85\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  3470.0\n",
      "Average reward:  -0.2\n",
      "--------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 433      |\n",
      "|    iterations         | 11200    |\n",
      "|    time_elapsed       | 129      |\n",
      "|    total_timesteps    | 56000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0614  |\n",
      "|    explained_variance | 0.0622   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 11199    |\n",
      "|    policy_loss        | 0.0162   |\n",
      "|    value_loss         | 0.695    |\n",
      "------------------------------------\n",
      "--------------------\n",
      "Number of steps:  3480.0\n",
      "Average reward:  -0.2\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  3490.0\n",
      "Average reward:  -0.05\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  3500.0\n",
      "Average reward:  0.85\n",
      "--------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 434       |\n",
      "|    iterations         | 11300     |\n",
      "|    time_elapsed       | 130       |\n",
      "|    total_timesteps    | 56500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.77e-05 |\n",
      "|    explained_variance | -0.0773   |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 11299     |\n",
      "|    policy_loss        | -6.03e-08 |\n",
      "|    value_loss         | 0.000145  |\n",
      "-------------------------------------\n",
      "--------------------\n",
      "Number of steps:  3510.0\n",
      "Average reward:  -0.05\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  3520.0\n",
      "Average reward:  0.25\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  3530.0\n",
      "Average reward:  0.25\n",
      "--------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 433      |\n",
      "|    iterations         | 11400    |\n",
      "|    time_elapsed       | 131      |\n",
      "|    total_timesteps    | 57000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0442  |\n",
      "|    explained_variance | 0.0348   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 11399    |\n",
      "|    policy_loss        | 0.0109   |\n",
      "|    value_loss         | 0.717    |\n",
      "------------------------------------\n",
      "--------------------\n",
      "Number of steps:  3540.0\n",
      "Average reward:  0.4\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  3550.0\n",
      "Average reward:  -0.35\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  3560.0\n",
      "Average reward:  1.0\n",
      "--------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 433      |\n",
      "|    iterations         | 11500    |\n",
      "|    time_elapsed       | 132      |\n",
      "|    total_timesteps    | 57500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0321  |\n",
      "|    explained_variance | 0.0302   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 11499    |\n",
      "|    policy_loss        | 0.00692  |\n",
      "|    value_loss         | 0.166    |\n",
      "------------------------------------\n",
      "--------------------\n",
      "Number of steps:  3570.0\n",
      "Average reward:  0.7\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  3580.0\n",
      "Average reward:  -0.05\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  3590.0\n",
      "Average reward:  1.0\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  3600.0\n",
      "Average reward:  0.4\n",
      "--------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 433       |\n",
      "|    iterations         | 11600     |\n",
      "|    time_elapsed       | 133       |\n",
      "|    total_timesteps    | 58000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.72e-05 |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 11599     |\n",
      "|    policy_loss        | -2.91e-08 |\n",
      "|    value_loss         | 0.00114   |\n",
      "-------------------------------------\n",
      "--------------------\n",
      "Number of steps:  3610.0\n",
      "Average reward:  0.4\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  3620.0\n",
      "Average reward:  0.7\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  3630.0\n",
      "Average reward:  0.4\n",
      "--------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 433       |\n",
      "|    iterations         | 11700     |\n",
      "|    time_elapsed       | 134       |\n",
      "|    total_timesteps    | 58500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.29e-05 |\n",
      "|    explained_variance | -5.59     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 11699     |\n",
      "|    policy_loss        | 3.98e-08  |\n",
      "|    value_loss         | 0.00375   |\n",
      "-------------------------------------\n",
      "--------------------\n",
      "Number of steps:  3640.0\n",
      "Average reward:  0.7\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  3650.0\n",
      "Average reward:  1.0\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  3660.0\n",
      "Average reward:  -0.05\n",
      "--------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 433      |\n",
      "|    iterations         | 11800    |\n",
      "|    time_elapsed       | 136      |\n",
      "|    total_timesteps    | 59000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00704 |\n",
      "|    explained_variance | -6.76    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 11799    |\n",
      "|    policy_loss        | 0.000794 |\n",
      "|    value_loss         | 0.78     |\n",
      "------------------------------------\n",
      "--------------------\n",
      "Number of steps:  3670.0\n",
      "Average reward:  0.85\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  3680.0\n",
      "Average reward:  -0.35\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  3690.0\n",
      "Average reward:  0.55\n",
      "--------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 433      |\n",
      "|    iterations         | 11900    |\n",
      "|    time_elapsed       | 137      |\n",
      "|    total_timesteps    | 59500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00607 |\n",
      "|    explained_variance | 0.53     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 11899    |\n",
      "|    policy_loss        | 0.000506 |\n",
      "|    value_loss         | 0.0703   |\n",
      "------------------------------------\n",
      "--------------------\n",
      "Number of steps:  3700.0\n",
      "Average reward:  0.85\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  3710.0\n",
      "Average reward:  0.7\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  3720.0\n",
      "Average reward:  0.1\n",
      "--------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 433       |\n",
      "|    iterations         | 12000     |\n",
      "|    time_elapsed       | 138       |\n",
      "|    total_timesteps    | 60000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.69e-06 |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 11999     |\n",
      "|    policy_loss        | -1.54e-08 |\n",
      "|    value_loss         | 0.00127   |\n",
      "-------------------------------------\n",
      "--------------------\n",
      "Number of steps:  3730.0\n",
      "Average reward:  -0.2\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  3740.0\n",
      "Average reward:  0.55\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  3750.0\n",
      "Average reward:  0.7\n",
      "--------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 433       |\n",
      "|    iterations         | 12100     |\n",
      "|    time_elapsed       | 139       |\n",
      "|    total_timesteps    | 60500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.71e-06 |\n",
      "|    explained_variance | -0.188    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 12099     |\n",
      "|    policy_loss        | 8.57e-10  |\n",
      "|    value_loss         | 0.000358  |\n",
      "-------------------------------------\n",
      "--------------------\n",
      "Number of steps:  3760.0\n",
      "Average reward:  0.25\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  3770.0\n",
      "Average reward:  0.55\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  3780.0\n",
      "Average reward:  0.1\n",
      "--------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 433       |\n",
      "|    iterations         | 12200     |\n",
      "|    time_elapsed       | 140       |\n",
      "|    total_timesteps    | 61000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.00527  |\n",
      "|    explained_variance | -472      |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 12199     |\n",
      "|    policy_loss        | -0.000771 |\n",
      "|    value_loss         | 0.401     |\n",
      "-------------------------------------\n",
      "--------------------\n",
      "Number of steps:  3790.0\n",
      "Average reward:  -0.05\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  3800.0\n",
      "Average reward:  0.7\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  3810.0\n",
      "Average reward:  0.55\n",
      "--------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 434      |\n",
      "|    iterations         | 12300    |\n",
      "|    time_elapsed       | 141      |\n",
      "|    total_timesteps    | 61500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00256 |\n",
      "|    explained_variance | 0.5      |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 12299    |\n",
      "|    policy_loss        | 0.000201 |\n",
      "|    value_loss         | 0.0758   |\n",
      "------------------------------------\n",
      "--------------------\n",
      "Number of steps:  3820.0\n",
      "Average reward:  0.85\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  3830.0\n",
      "Average reward:  -0.2\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  3840.0\n",
      "Average reward:  -0.35\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  3850.0\n",
      "Average reward:  0.1\n",
      "--------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 434      |\n",
      "|    iterations         | 12400    |\n",
      "|    time_elapsed       | 142      |\n",
      "|    total_timesteps    | 62000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.276   |\n",
      "|    explained_variance | 0.73     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 12399    |\n",
      "|    policy_loss        | 0.131    |\n",
      "|    value_loss         | 0.0887   |\n",
      "------------------------------------\n",
      "--------------------\n",
      "Number of steps:  3860.0\n",
      "Average reward:  0.85\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  3870.0\n",
      "Average reward:  0.7\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  3880.0\n",
      "Average reward:  -0.5\n",
      "--------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 433      |\n",
      "|    iterations         | 12500    |\n",
      "|    time_elapsed       | 144      |\n",
      "|    total_timesteps    | 62500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0827  |\n",
      "|    explained_variance | -108     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 12499    |\n",
      "|    policy_loss        | -0.00474 |\n",
      "|    value_loss         | 0.146    |\n",
      "------------------------------------\n",
      "--------------------\n",
      "Number of steps:  3890.0\n",
      "Average reward:  -0.2\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  3900.0\n",
      "Average reward:  1.0\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  3910.0\n",
      "Average reward:  0.1\n",
      "--------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 433       |\n",
      "|    iterations         | 12600     |\n",
      "|    time_elapsed       | 145       |\n",
      "|    total_timesteps    | 63000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.64e-05 |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 12599     |\n",
      "|    policy_loss        | 3.91e-07  |\n",
      "|    value_loss         | 0.0424    |\n",
      "-------------------------------------\n",
      "--------------------\n",
      "Number of steps:  3920.0\n",
      "Average reward:  0.4\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  3930.0\n",
      "Average reward:  -0.35\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  3940.0\n",
      "Average reward:  -0.05\n",
      "--------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 433      |\n",
      "|    iterations         | 12700    |\n",
      "|    time_elapsed       | 146      |\n",
      "|    total_timesteps    | 63500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.102   |\n",
      "|    explained_variance | -11.5    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 12699    |\n",
      "|    policy_loss        | 0.0344   |\n",
      "|    value_loss         | 0.835    |\n",
      "------------------------------------\n",
      "--------------------\n",
      "Number of steps:  3950.0\n",
      "Average reward:  0.7\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  3960.0\n",
      "Average reward:  -0.45\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  3970.0\n",
      "Average reward:  -0.45\n",
      "--------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 433       |\n",
      "|    iterations         | 12800     |\n",
      "|    time_elapsed       | 147       |\n",
      "|    total_timesteps    | 64000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000252 |\n",
      "|    explained_variance | -1.8      |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 12799     |\n",
      "|    policy_loss        | -1.89e-07 |\n",
      "|    value_loss         | 0.000117  |\n",
      "-------------------------------------\n",
      "--------------------\n",
      "Number of steps:  3980.0\n",
      "Average reward:  0.1\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  3990.0\n",
      "Average reward:  0.45\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  4000.0\n",
      "Average reward:  0.1\n",
      "--------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 434       |\n",
      "|    iterations         | 12900     |\n",
      "|    time_elapsed       | 148       |\n",
      "|    total_timesteps    | 64500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000127 |\n",
      "|    explained_variance | -2.92     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 12899     |\n",
      "|    policy_loss        | 1.9e-09   |\n",
      "|    value_loss         | 0.000112  |\n",
      "-------------------------------------\n",
      "--------------------\n",
      "Number of steps:  4010.0\n",
      "Average reward:  -0.15\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  4020.0\n",
      "Average reward:  0.4\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  4030.0\n",
      "Average reward:  0.1\n",
      "--------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 434       |\n",
      "|    iterations         | 13000     |\n",
      "|    time_elapsed       | 149       |\n",
      "|    total_timesteps    | 65000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000274 |\n",
      "|    explained_variance | -10       |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 12999     |\n",
      "|    policy_loss        | 7.18e-08  |\n",
      "|    value_loss         | 1.2e-05   |\n",
      "-------------------------------------\n",
      "--------------------\n",
      "Number of steps:  4040.0\n",
      "Average reward:  0.0\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  4050.0\n",
      "Average reward:  0.1\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  4060.0\n",
      "Average reward:  0.4\n",
      "--------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 434       |\n",
      "|    iterations         | 13100     |\n",
      "|    time_elapsed       | 150       |\n",
      "|    total_timesteps    | 65500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000185 |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 13099     |\n",
      "|    policy_loss        | 1.26e-06  |\n",
      "|    value_loss         | 0.0068    |\n",
      "-------------------------------------\n",
      "--------------------\n",
      "Number of steps:  4070.0\n",
      "Average reward:  -0.35\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  4080.0\n",
      "Average reward:  0.4\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  4090.0\n",
      "Average reward:  -0.05\n",
      "--------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 434       |\n",
      "|    iterations         | 13200     |\n",
      "|    time_elapsed       | 151       |\n",
      "|    total_timesteps    | 66000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000301 |\n",
      "|    explained_variance | -23.9     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 13199     |\n",
      "|    policy_loss        | -2.42e-07 |\n",
      "|    value_loss         | 0.000331  |\n",
      "-------------------------------------\n",
      "--------------------\n",
      "Number of steps:  4100.0\n",
      "Average reward:  0.25\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  4110.0\n",
      "Average reward:  0.1\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  4120.0\n",
      "Average reward:  0.25\n",
      "--------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 434       |\n",
      "|    iterations         | 13300     |\n",
      "|    time_elapsed       | 153       |\n",
      "|    total_timesteps    | 66500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000164 |\n",
      "|    explained_variance | -8.49     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 13299     |\n",
      "|    policy_loss        | 4.86e-08  |\n",
      "|    value_loss         | 9.6e-05   |\n",
      "-------------------------------------\n",
      "--------------------\n",
      "Number of steps:  4130.0\n",
      "Average reward:  1.0\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  4140.0\n",
      "Average reward:  0.55\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  4150.0\n",
      "Average reward:  -0.35\n",
      "--------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 434       |\n",
      "|    iterations         | 13400     |\n",
      "|    time_elapsed       | 154       |\n",
      "|    total_timesteps    | 67000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -9.03e-05 |\n",
      "|    explained_variance | -0.839    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 13399     |\n",
      "|    policy_loss        | 8.05e-08  |\n",
      "|    value_loss         | 0.000213  |\n",
      "-------------------------------------\n",
      "--------------------\n",
      "Number of steps:  4160.0\n",
      "Average reward:  0.85\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  4170.0\n",
      "Average reward:  -0.5\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  4180.0\n",
      "Average reward:  0.4\n",
      "--------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 434       |\n",
      "|    iterations         | 13500     |\n",
      "|    time_elapsed       | 155       |\n",
      "|    total_timesteps    | 67500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.3e-05  |\n",
      "|    explained_variance | -2.21     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 13499     |\n",
      "|    policy_loss        | -2.16e-08 |\n",
      "|    value_loss         | 8.95e-05  |\n",
      "-------------------------------------\n",
      "--------------------\n",
      "Number of steps:  4190.0\n",
      "Average reward:  0.55\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  4200.0\n",
      "Average reward:  0.7\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  4210.0\n",
      "Average reward:  0.1\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  4220.0\n",
      "Average reward:  0.4\n",
      "--------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 434      |\n",
      "|    iterations         | 13600    |\n",
      "|    time_elapsed       | 156      |\n",
      "|    total_timesteps    | 68000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0205  |\n",
      "|    explained_variance | 0.0537   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 13599    |\n",
      "|    policy_loss        | 0.00385  |\n",
      "|    value_loss         | 0.533    |\n",
      "------------------------------------\n",
      "--------------------\n",
      "Number of steps:  4230.0\n",
      "Average reward:  0.55\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  4240.0\n",
      "Average reward:  -0.05\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  4250.0\n",
      "Average reward:  1.0\n",
      "--------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 434       |\n",
      "|    iterations         | 13700     |\n",
      "|    time_elapsed       | 157       |\n",
      "|    total_timesteps    | 68500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.14e-05 |\n",
      "|    explained_variance | -9.85     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 13699     |\n",
      "|    policy_loss        | -7.88e-08 |\n",
      "|    value_loss         | 0.00499   |\n",
      "-------------------------------------\n",
      "--------------------\n",
      "Number of steps:  4260.0\n",
      "Average reward:  0.4\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  4270.0\n",
      "Average reward:  0.85\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  4280.0\n",
      "Average reward:  0.55\n",
      "--------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 434       |\n",
      "|    iterations         | 13800     |\n",
      "|    time_elapsed       | 158       |\n",
      "|    total_timesteps    | 69000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.39e-05 |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 13799     |\n",
      "|    policy_loss        | 4.23e-08  |\n",
      "|    value_loss         | 0.00237   |\n",
      "-------------------------------------\n",
      "--------------------\n",
      "Number of steps:  4290.0\n",
      "Average reward:  0.4\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  4300.0\n",
      "Average reward:  0.4\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  4310.0\n",
      "Average reward:  1.0\n",
      "--------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 434       |\n",
      "|    iterations         | 13900     |\n",
      "|    time_elapsed       | 159       |\n",
      "|    total_timesteps    | 69500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.81e-05 |\n",
      "|    explained_variance | -2.93     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 13899     |\n",
      "|    policy_loss        | 5.09e-08  |\n",
      "|    value_loss         | 0.00352   |\n",
      "-------------------------------------\n",
      "--------------------\n",
      "Number of steps:  4320.0\n",
      "Average reward:  0.7\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  4330.0\n",
      "Average reward:  0.4\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  4340.0\n",
      "Average reward:  0.1\n",
      "--------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 434       |\n",
      "|    iterations         | 14000     |\n",
      "|    time_elapsed       | 161       |\n",
      "|    total_timesteps    | 70000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.42e-05 |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 13999     |\n",
      "|    policy_loss        | 4.43e-07  |\n",
      "|    value_loss         | 0.217     |\n",
      "-------------------------------------\n",
      "--------------------\n",
      "Number of steps:  4350.0\n",
      "Average reward:  0.1\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  4360.0\n",
      "Average reward:  0.1\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  4370.0\n",
      "Average reward:  0.4\n",
      "--------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 432      |\n",
      "|    iterations         | 14100    |\n",
      "|    time_elapsed       | 163      |\n",
      "|    total_timesteps    | 70500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0156  |\n",
      "|    explained_variance | -1.91    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 14099    |\n",
      "|    policy_loss        | -0.00341 |\n",
      "|    value_loss         | 0.32     |\n",
      "------------------------------------\n",
      "--------------------\n",
      "Number of steps:  4380.0\n",
      "Average reward:  -0.5\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  4390.0\n",
      "Average reward:  0.1\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  4400.0\n",
      "Average reward:  -0.15\n",
      "--------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 432       |\n",
      "|    iterations         | 14200     |\n",
      "|    time_elapsed       | 164       |\n",
      "|    total_timesteps    | 71000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000337 |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 14199     |\n",
      "|    policy_loss        | 3.74e-07  |\n",
      "|    value_loss         | 0.000216  |\n",
      "-------------------------------------\n",
      "--------------------\n",
      "Number of steps:  4410.0\n",
      "Average reward:  0.25\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  4420.0\n",
      "Average reward:  0.2\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  4430.0\n",
      "Average reward:  0.45\n",
      "--------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 432       |\n",
      "|    iterations         | 14300     |\n",
      "|    time_elapsed       | 165       |\n",
      "|    total_timesteps    | 71500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000389 |\n",
      "|    explained_variance | -8.1      |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 14299     |\n",
      "|    policy_loss        | -1.14e-06 |\n",
      "|    value_loss         | 0.00163   |\n",
      "-------------------------------------\n",
      "--------------------\n",
      "Number of steps:  4440.0\n",
      "Average reward:  -0.3\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  4450.0\n",
      "Average reward:  0.25\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  4460.0\n",
      "Average reward:  0.55\n",
      "--------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 432      |\n",
      "|    iterations         | 14400    |\n",
      "|    time_elapsed       | 166      |\n",
      "|    total_timesteps    | 72000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.111   |\n",
      "|    explained_variance | -0.0455  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 14399    |\n",
      "|    policy_loss        | -0.0311  |\n",
      "|    value_loss         | 0.224    |\n",
      "------------------------------------\n",
      "--------------------\n",
      "Number of steps:  4470.0\n",
      "Average reward:  0.4\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  4480.0\n",
      "Average reward:  0.55\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  4490.0\n",
      "Average reward:  0.4\n",
      "--------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 432      |\n",
      "|    iterations         | 14500    |\n",
      "|    time_elapsed       | 167      |\n",
      "|    total_timesteps    | 72500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0535  |\n",
      "|    explained_variance | 0.177    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 14499    |\n",
      "|    policy_loss        | 0.0127   |\n",
      "|    value_loss         | 0.136    |\n",
      "------------------------------------\n",
      "--------------------\n",
      "Number of steps:  4500.0\n",
      "Average reward:  0.85\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  4510.0\n",
      "Average reward:  0.25\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  4520.0\n",
      "Average reward:  1.0\n",
      "--------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 432       |\n",
      "|    iterations         | 14600     |\n",
      "|    time_elapsed       | 168       |\n",
      "|    total_timesteps    | 73000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.15e-05 |\n",
      "|    explained_variance | -6.99     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 14599     |\n",
      "|    policy_loss        | -1.05e-07 |\n",
      "|    value_loss         | 0.00688   |\n",
      "-------------------------------------\n",
      "--------------------\n",
      "Number of steps:  4530.0\n",
      "Average reward:  0.25\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  4540.0\n",
      "Average reward:  0.1\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  4550.0\n",
      "Average reward:  1.0\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  4560.0\n",
      "Average reward:  0.25\n",
      "--------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 432       |\n",
      "|    iterations         | 14700     |\n",
      "|    time_elapsed       | 170       |\n",
      "|    total_timesteps    | 73500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.54e-05 |\n",
      "|    explained_variance | -3.28     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 14699     |\n",
      "|    policy_loss        | 5.73e-08  |\n",
      "|    value_loss         | 0.00539   |\n",
      "-------------------------------------\n",
      "--------------------\n",
      "Number of steps:  4570.0\n",
      "Average reward:  -0.5\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  4580.0\n",
      "Average reward:  0.55\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  4590.0\n",
      "Average reward:  0.55\n",
      "--------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 432       |\n",
      "|    iterations         | 14800     |\n",
      "|    time_elapsed       | 171       |\n",
      "|    total_timesteps    | 74000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.28e-05 |\n",
      "|    explained_variance | -0.51     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 14799     |\n",
      "|    policy_loss        | -3.02e-08 |\n",
      "|    value_loss         | 0.000846  |\n",
      "-------------------------------------\n",
      "--------------------\n",
      "Number of steps:  4600.0\n",
      "Average reward:  0.1\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  4610.0\n",
      "Average reward:  -0.5\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  4620.0\n",
      "Average reward:  0.7\n",
      "--------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 432      |\n",
      "|    iterations         | 14900    |\n",
      "|    time_elapsed       | 172      |\n",
      "|    total_timesteps    | 74500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0763  |\n",
      "|    explained_variance | -13.4    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 14899    |\n",
      "|    policy_loss        | -0.00522 |\n",
      "|    value_loss         | 0.0183   |\n",
      "------------------------------------\n",
      "--------------------\n",
      "Number of steps:  4630.0\n",
      "Average reward:  0.1\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  4640.0\n",
      "Average reward:  -0.05\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  4650.0\n",
      "Average reward:  0.55\n",
      "--------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 432      |\n",
      "|    iterations         | 15000    |\n",
      "|    time_elapsed       | 173      |\n",
      "|    total_timesteps    | 75000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.212   |\n",
      "|    explained_variance | -22.9    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 14999    |\n",
      "|    policy_loss        | -0.215   |\n",
      "|    value_loss         | 0.0169   |\n",
      "------------------------------------\n",
      "--------------------\n",
      "Number of steps:  4660.0\n",
      "Average reward:  -0.15\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  4670.0\n",
      "Average reward:  -0.5\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  4680.0\n",
      "Average reward:  -0.2\n",
      "--------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 432       |\n",
      "|    iterations         | 15100     |\n",
      "|    time_elapsed       | 174       |\n",
      "|    total_timesteps    | 75500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000108 |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 15099     |\n",
      "|    policy_loss        | 1.12e-06  |\n",
      "|    value_loss         | 0.0171    |\n",
      "-------------------------------------\n",
      "--------------------\n",
      "Number of steps:  4690.0\n",
      "Average reward:  0.7\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  4700.0\n",
      "Average reward:  0.1\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  4710.0\n",
      "Average reward:  0.55\n",
      "--------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 433      |\n",
      "|    iterations         | 15200    |\n",
      "|    time_elapsed       | 175      |\n",
      "|    total_timesteps    | 76000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0321  |\n",
      "|    explained_variance | 0.081    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 15199    |\n",
      "|    policy_loss        | 0.00655  |\n",
      "|    value_loss         | 0.318    |\n",
      "------------------------------------\n",
      "--------------------\n",
      "Number of steps:  4720.0\n",
      "Average reward:  0.4\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  4730.0\n",
      "Average reward:  0.25\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  4740.0\n",
      "Average reward:  -0.2\n",
      "--------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 432      |\n",
      "|    iterations         | 15300    |\n",
      "|    time_elapsed       | 176      |\n",
      "|    total_timesteps    | 76500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0588  |\n",
      "|    explained_variance | -0.283   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 15299    |\n",
      "|    policy_loss        | -0.415   |\n",
      "|    value_loss         | 0.147    |\n",
      "------------------------------------\n",
      "--------------------\n",
      "Number of steps:  4750.0\n",
      "Average reward:  0.1\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  4760.0\n",
      "Average reward:  -0.05\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  4770.0\n",
      "Average reward:  0.1\n",
      "--------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 432       |\n",
      "|    iterations         | 15400     |\n",
      "|    time_elapsed       | 177       |\n",
      "|    total_timesteps    | 77000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.01e-05 |\n",
      "|    explained_variance | -5.37     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 15399     |\n",
      "|    policy_loss        | -5.91e-08 |\n",
      "|    value_loss         | 0.000448  |\n",
      "-------------------------------------\n",
      "--------------------\n",
      "Number of steps:  4780.0\n",
      "Average reward:  0.7\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  4790.0\n",
      "Average reward:  -0.2\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  4800.0\n",
      "Average reward:  -0.2\n",
      "--------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 433       |\n",
      "|    iterations         | 15500     |\n",
      "|    time_elapsed       | 178       |\n",
      "|    total_timesteps    | 77500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000152 |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 15499     |\n",
      "|    policy_loss        | -6.99e-08 |\n",
      "|    value_loss         | 3.86e-05  |\n",
      "-------------------------------------\n",
      "--------------------\n",
      "Number of steps:  4810.0\n",
      "Average reward:  0.7\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  4820.0\n",
      "Average reward:  0.1\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  4830.0\n",
      "Average reward:  0.55\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  4840.0\n",
      "Average reward:  -0.45\n",
      "--------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 432      |\n",
      "|    iterations         | 15600    |\n",
      "|    time_elapsed       | 180      |\n",
      "|    total_timesteps    | 78000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.244   |\n",
      "|    explained_variance | -0.0218  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 15599    |\n",
      "|    policy_loss        | -0.156   |\n",
      "|    value_loss         | 0.0999   |\n",
      "------------------------------------\n",
      "--------------------\n",
      "Number of steps:  4850.0\n",
      "Average reward:  1.0\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  4860.0\n",
      "Average reward:  -0.35\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  4870.0\n",
      "Average reward:  0.1\n",
      "--------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 432       |\n",
      "|    iterations         | 15700     |\n",
      "|    time_elapsed       | 181       |\n",
      "|    total_timesteps    | 78500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000137 |\n",
      "|    explained_variance | -6.83     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 15699     |\n",
      "|    policy_loss        | 6.21e-08  |\n",
      "|    value_loss         | 4.81e-05  |\n",
      "-------------------------------------\n",
      "--------------------\n",
      "Number of steps:  4880.0\n",
      "Average reward:  0.85\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  4890.0\n",
      "Average reward:  0.1\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  4900.0\n",
      "Average reward:  0.55\n",
      "--------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 432       |\n",
      "|    iterations         | 15800     |\n",
      "|    time_elapsed       | 182       |\n",
      "|    total_timesteps    | 79000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.77e-05 |\n",
      "|    explained_variance | -3.46     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 15799     |\n",
      "|    policy_loss        | -3.73e-08 |\n",
      "|    value_loss         | 0.000133  |\n",
      "-------------------------------------\n",
      "--------------------\n",
      "Number of steps:  4910.0\n",
      "Average reward:  0.7\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  4920.0\n",
      "Average reward:  -0.05\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  4930.0\n",
      "Average reward:  0.85\n",
      "--------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 432       |\n",
      "|    iterations         | 15900     |\n",
      "|    time_elapsed       | 183       |\n",
      "|    total_timesteps    | 79500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.68e-05 |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 15899     |\n",
      "|    policy_loss        | 1.17e-08  |\n",
      "|    value_loss         | 0.000256  |\n",
      "-------------------------------------\n",
      "--------------------\n",
      "Number of steps:  4940.0\n",
      "Average reward:  0.85\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  4950.0\n",
      "Average reward:  0.7\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  4960.0\n",
      "Average reward:  0.4\n",
      "--------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 432       |\n",
      "|    iterations         | 16000     |\n",
      "|    time_elapsed       | 184       |\n",
      "|    total_timesteps    | 80000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.26e-05 |\n",
      "|    explained_variance | -3.41     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 15999     |\n",
      "|    policy_loss        | -1.01e-08 |\n",
      "|    value_loss         | 0.000878  |\n",
      "-------------------------------------\n",
      "--------------------\n",
      "Number of steps:  4970.0\n",
      "Average reward:  -0.05\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  4980.0\n",
      "Average reward:  0.4\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  4990.0\n",
      "Average reward:  -0.05\n",
      "--------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 432      |\n",
      "|    iterations         | 16100    |\n",
      "|    time_elapsed       | 186      |\n",
      "|    total_timesteps    | 80500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00668 |\n",
      "|    explained_variance | 0.0918   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 16099    |\n",
      "|    policy_loss        | 0.000884 |\n",
      "|    value_loss         | 0.489    |\n",
      "------------------------------------\n",
      "--------------------\n",
      "Number of steps:  5000.0\n",
      "Average reward:  0.4\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  5010.0\n",
      "Average reward:  0.7\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  5020.0\n",
      "Average reward:  0.25\n",
      "--------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 432       |\n",
      "|    iterations         | 16200     |\n",
      "|    time_elapsed       | 187       |\n",
      "|    total_timesteps    | 81000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.14e-05 |\n",
      "|    explained_variance | -7.79     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 16199     |\n",
      "|    policy_loss        | -2.55e-08 |\n",
      "|    value_loss         | 0.00146   |\n",
      "-------------------------------------\n",
      "--------------------\n",
      "Number of steps:  5030.0\n",
      "Average reward:  -0.5\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  5040.0\n",
      "Average reward:  0.7\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  5050.0\n",
      "Average reward:  0.25\n",
      "--------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 432       |\n",
      "|    iterations         | 16300     |\n",
      "|    time_elapsed       | 188       |\n",
      "|    total_timesteps    | 81500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.09e-05 |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 16299     |\n",
      "|    policy_loss        | 1.63e-08  |\n",
      "|    value_loss         | 0.00132   |\n",
      "-------------------------------------\n",
      "--------------------\n",
      "Number of steps:  5060.0\n",
      "Average reward:  0.55\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  5070.0\n",
      "Average reward:  -0.35\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  5080.0\n",
      "Average reward:  -0.5\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  5090.0\n",
      "Average reward:  0.55\n",
      "--------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 432       |\n",
      "|    iterations         | 16400     |\n",
      "|    time_elapsed       | 189       |\n",
      "|    total_timesteps    | 82000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.67e-05 |\n",
      "|    explained_variance | -1.88     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 16399     |\n",
      "|    policy_loss        | 2.97e-08  |\n",
      "|    value_loss         | 0.00038   |\n",
      "-------------------------------------\n",
      "--------------------\n",
      "Number of steps:  5100.0\n",
      "Average reward:  0.25\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  5110.0\n",
      "Average reward:  0.55\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  5120.0\n",
      "Average reward:  0.7\n",
      "--------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 432       |\n",
      "|    iterations         | 16500     |\n",
      "|    time_elapsed       | 190       |\n",
      "|    total_timesteps    | 82500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.67e-05 |\n",
      "|    explained_variance | -4.61     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 16499     |\n",
      "|    policy_loss        | 1.92e-08  |\n",
      "|    value_loss         | 0.00149   |\n",
      "-------------------------------------\n",
      "--------------------\n",
      "Number of steps:  5130.0\n",
      "Average reward:  -0.5\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  5140.0\n",
      "Average reward:  -0.2\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  5150.0\n",
      "Average reward:  -0.05\n",
      "--------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 432       |\n",
      "|    iterations         | 16600     |\n",
      "|    time_elapsed       | 191       |\n",
      "|    total_timesteps    | 83000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.94e-05 |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 16599     |\n",
      "|    policy_loss        | 3.58e-07  |\n",
      "|    value_loss         | 0.0353    |\n",
      "-------------------------------------\n",
      "--------------------\n",
      "Number of steps:  5160.0\n",
      "Average reward:  1.0\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  5170.0\n",
      "Average reward:  0.55\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  5180.0\n",
      "Average reward:  -0.05\n",
      "--------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 432      |\n",
      "|    iterations         | 16700    |\n",
      "|    time_elapsed       | 193      |\n",
      "|    total_timesteps    | 83500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0121  |\n",
      "|    explained_variance | 0.156    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 16699    |\n",
      "|    policy_loss        | 0.0017   |\n",
      "|    value_loss         | 0.29     |\n",
      "------------------------------------\n",
      "--------------------\n",
      "Number of steps:  5190.0\n",
      "Average reward:  1.0\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  5200.0\n",
      "Average reward:  1.0\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  5210.0\n",
      "Average reward:  0.1\n",
      "--------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 432       |\n",
      "|    iterations         | 16800     |\n",
      "|    time_elapsed       | 194       |\n",
      "|    total_timesteps    | 84000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -8.49e-06 |\n",
      "|    explained_variance | -8.79     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 16799     |\n",
      "|    policy_loss        | -2.15e-08 |\n",
      "|    value_loss         | 0.00383   |\n",
      "-------------------------------------\n",
      "--------------------\n",
      "Number of steps:  5220.0\n",
      "Average reward:  0.1\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  5230.0\n",
      "Average reward:  -0.05\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  5240.0\n",
      "Average reward:  -0.5\n",
      "--------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 432       |\n",
      "|    iterations         | 16900     |\n",
      "|    time_elapsed       | 195       |\n",
      "|    total_timesteps    | 84500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.19e-05 |\n",
      "|    explained_variance | -0.587    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 16899     |\n",
      "|    policy_loss        | 1.53e-08  |\n",
      "|    value_loss         | 0.000212  |\n",
      "-------------------------------------\n",
      "--------------------\n",
      "Number of steps:  5250.0\n",
      "Average reward:  0.4\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  5260.0\n",
      "Average reward:  0.55\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  5270.0\n",
      "Average reward:  0.4\n",
      "--------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 432       |\n",
      "|    iterations         | 17000     |\n",
      "|    time_elapsed       | 196       |\n",
      "|    total_timesteps    | 85000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.34e-05 |\n",
      "|    explained_variance | -3.9      |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 16999     |\n",
      "|    policy_loss        | -1.12e-08 |\n",
      "|    value_loss         | 0.000628  |\n",
      "-------------------------------------\n",
      "--------------------\n",
      "Number of steps:  5280.0\n",
      "Average reward:  0.1\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  5290.0\n",
      "Average reward:  0.85\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  5300.0\n",
      "Average reward:  -0.2\n",
      "--------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 432      |\n",
      "|    iterations         | 17100    |\n",
      "|    time_elapsed       | 197      |\n",
      "|    total_timesteps    | 85500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.012   |\n",
      "|    explained_variance | 0.116    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 17099    |\n",
      "|    policy_loss        | 0.00171  |\n",
      "|    value_loss         | 0.486    |\n",
      "------------------------------------\n",
      "--------------------\n",
      "Number of steps:  5310.0\n",
      "Average reward:  0.1\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  5320.0\n",
      "Average reward:  0.4\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  5330.0\n",
      "Average reward:  0.4\n",
      "--------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 432       |\n",
      "|    iterations         | 17200     |\n",
      "|    time_elapsed       | 198       |\n",
      "|    total_timesteps    | 86000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.01e-05 |\n",
      "|    explained_variance | -11.6     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 17199     |\n",
      "|    policy_loss        | -2.4e-08  |\n",
      "|    value_loss         | 0.00425   |\n",
      "-------------------------------------\n",
      "--------------------\n",
      "Number of steps:  5340.0\n",
      "Average reward:  0.55\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  5350.0\n",
      "Average reward:  0.4\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  5360.0\n",
      "Average reward:  0.4\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  5370.0\n",
      "Average reward:  0.1\n",
      "--------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 431       |\n",
      "|    iterations         | 17300     |\n",
      "|    time_elapsed       | 200       |\n",
      "|    total_timesteps    | 86500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -8.76e-06 |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 17299     |\n",
      "|    policy_loss        | 1.11e-08  |\n",
      "|    value_loss         | 0.000694  |\n",
      "-------------------------------------\n",
      "--------------------\n",
      "Number of steps:  5380.0\n",
      "Average reward:  0.25\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  5390.0\n",
      "Average reward:  0.25\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  5400.0\n",
      "Average reward:  1.0\n",
      "--------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 431       |\n",
      "|    iterations         | 17400     |\n",
      "|    time_elapsed       | 201       |\n",
      "|    total_timesteps    | 87000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.09e-06 |\n",
      "|    explained_variance | -0.697    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 17399     |\n",
      "|    policy_loss        | -1.09e-08 |\n",
      "|    value_loss         | 0.00108   |\n",
      "-------------------------------------\n",
      "--------------------\n",
      "Number of steps:  5410.0\n",
      "Average reward:  0.4\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  5420.0\n",
      "Average reward:  -0.5\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  5430.0\n",
      "Average reward:  0.1\n",
      "--------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 431      |\n",
      "|    iterations         | 17500    |\n",
      "|    time_elapsed       | 202      |\n",
      "|    total_timesteps    | 87500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00727 |\n",
      "|    explained_variance | 0.157    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 17499    |\n",
      "|    policy_loss        | 0.000782 |\n",
      "|    value_loss         | 0.454    |\n",
      "------------------------------------\n",
      "--------------------\n",
      "Number of steps:  5440.0\n",
      "Average reward:  0.4\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  5450.0\n",
      "Average reward:  0.1\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  5460.0\n",
      "Average reward:  -0.5\n",
      "--------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 431      |\n",
      "|    iterations         | 17600    |\n",
      "|    time_elapsed       | 203      |\n",
      "|    total_timesteps    | 88000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0523  |\n",
      "|    explained_variance | 0.293    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 17599    |\n",
      "|    policy_loss        | 0.0123   |\n",
      "|    value_loss         | 0.131    |\n",
      "------------------------------------\n",
      "--------------------\n",
      "Number of steps:  5470.0\n",
      "Average reward:  0.25\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  5480.0\n",
      "Average reward:  -0.05\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  5490.0\n",
      "Average reward:  0.1\n",
      "--------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 431      |\n",
      "|    iterations         | 17700    |\n",
      "|    time_elapsed       | 205      |\n",
      "|    total_timesteps    | 88500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.116   |\n",
      "|    explained_variance | 0.0739   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 17699    |\n",
      "|    policy_loss        | 0.0538   |\n",
      "|    value_loss         | 0.534    |\n",
      "------------------------------------\n",
      "--------------------\n",
      "Number of steps:  5500.0\n",
      "Average reward:  0.25\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  5510.0\n",
      "Average reward:  0.55\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  5520.0\n",
      "Average reward:  0.4\n",
      "--------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 431      |\n",
      "|    iterations         | 17800    |\n",
      "|    time_elapsed       | 206      |\n",
      "|    total_timesteps    | 89000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0386  |\n",
      "|    explained_variance | 0.0372   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 17799    |\n",
      "|    policy_loss        | 0.00869  |\n",
      "|    value_loss         | 0.321    |\n",
      "------------------------------------\n",
      "--------------------\n",
      "Number of steps:  5530.0\n",
      "Average reward:  1.0\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  5540.0\n",
      "Average reward:  0.55\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  5550.0\n",
      "Average reward:  0.7\n",
      "--------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 429       |\n",
      "|    iterations         | 17900     |\n",
      "|    time_elapsed       | 208       |\n",
      "|    total_timesteps    | 89500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.16e-05 |\n",
      "|    explained_variance | -9.65     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 17899     |\n",
      "|    policy_loss        | -5.61e-08 |\n",
      "|    value_loss         | 0.0071    |\n",
      "-------------------------------------\n",
      "--------------------\n",
      "Number of steps:  5560.0\n",
      "Average reward:  0.55\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  5570.0\n",
      "Average reward:  0.55\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  5580.0\n",
      "Average reward:  0.1\n",
      "--------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 429       |\n",
      "|    iterations         | 18000     |\n",
      "|    time_elapsed       | 209       |\n",
      "|    total_timesteps    | 90000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.56e-05 |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 17999     |\n",
      "|    policy_loss        | 2.54e-08  |\n",
      "|    value_loss         | 0.0009    |\n",
      "-------------------------------------\n",
      "--------------------\n",
      "Number of steps:  5590.0\n",
      "Average reward:  0.25\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  5600.0\n",
      "Average reward:  0.25\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  5610.0\n",
      "Average reward:  0.1\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  5620.0\n",
      "Average reward:  -0.2\n",
      "--------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 429       |\n",
      "|    iterations         | 18100     |\n",
      "|    time_elapsed       | 210       |\n",
      "|    total_timesteps    | 90500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.05e-05 |\n",
      "|    explained_variance | -0.882    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 18099     |\n",
      "|    policy_loss        | -1.62e-08 |\n",
      "|    value_loss         | 0.000171  |\n",
      "-------------------------------------\n",
      "--------------------\n",
      "Number of steps:  5630.0\n",
      "Average reward:  -0.5\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  5640.0\n",
      "Average reward:  0.1\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  5650.0\n",
      "Average reward:  0.45\n",
      "--------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 430      |\n",
      "|    iterations         | 18200    |\n",
      "|    time_elapsed       | 211      |\n",
      "|    total_timesteps    | 91000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.125   |\n",
      "|    explained_variance | 0.065    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 18199    |\n",
      "|    policy_loss        | 0.0639   |\n",
      "|    value_loss         | 0.686    |\n",
      "------------------------------------\n",
      "--------------------\n",
      "Number of steps:  5660.0\n",
      "Average reward:  0.55\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  5670.0\n",
      "Average reward:  -0.2\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  5680.0\n",
      "Average reward:  0.25\n",
      "--------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 429       |\n",
      "|    iterations         | 18300     |\n",
      "|    time_elapsed       | 212       |\n",
      "|    total_timesteps    | 91500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -3.31e-05 |\n",
      "|    explained_variance | -0.606    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 18299     |\n",
      "|    policy_loss        | -2.68e-08 |\n",
      "|    value_loss         | 0.000253  |\n",
      "-------------------------------------\n",
      "--------------------\n",
      "Number of steps:  5690.0\n",
      "Average reward:  0.85\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  5700.0\n",
      "Average reward:  -0.5\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  5710.0\n",
      "Average reward:  -0.35\n",
      "--------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 429      |\n",
      "|    iterations         | 18400    |\n",
      "|    time_elapsed       | 214      |\n",
      "|    total_timesteps    | 92000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0656  |\n",
      "|    explained_variance | -0.505   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 18399    |\n",
      "|    policy_loss        | -0.0159  |\n",
      "|    value_loss         | 0.257    |\n",
      "------------------------------------\n",
      "--------------------\n",
      "Number of steps:  5720.0\n",
      "Average reward:  -0.05\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  5730.0\n",
      "Average reward:  0.1\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  5740.0\n",
      "Average reward:  0.25\n",
      "--------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 429       |\n",
      "|    iterations         | 18500     |\n",
      "|    time_elapsed       | 215       |\n",
      "|    total_timesteps    | 92500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.78e-05 |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 18499     |\n",
      "|    policy_loss        | 6.99e-07  |\n",
      "|    value_loss         | 0.0178    |\n",
      "-------------------------------------\n",
      "--------------------\n",
      "Number of steps:  5750.0\n",
      "Average reward:  0.4\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  5760.0\n",
      "Average reward:  0.55\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  5770.0\n",
      "Average reward:  0.4\n",
      "--------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 429       |\n",
      "|    iterations         | 18600     |\n",
      "|    time_elapsed       | 216       |\n",
      "|    total_timesteps    | 93000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -8.6e-05  |\n",
      "|    explained_variance | -0.215    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 18599     |\n",
      "|    policy_loss        | -3.91e-08 |\n",
      "|    value_loss         | 4.8e-05   |\n",
      "-------------------------------------\n",
      "--------------------\n",
      "Number of steps:  5780.0\n",
      "Average reward:  -0.2\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  5790.0\n",
      "Average reward:  -0.45\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  5800.0\n",
      "Average reward:  -0.05\n",
      "--------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 429      |\n",
      "|    iterations         | 18700    |\n",
      "|    time_elapsed       | 217      |\n",
      "|    total_timesteps    | 93500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.13    |\n",
      "|    explained_variance | 0.0307   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 18699    |\n",
      "|    policy_loss        | 0.0814   |\n",
      "|    value_loss         | 0.755    |\n",
      "------------------------------------\n",
      "--------------------\n",
      "Number of steps:  5810.0\n",
      "Average reward:  0.25\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  5820.0\n",
      "Average reward:  0.25\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  5830.0\n",
      "Average reward:  -0.45\n",
      "--------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 429       |\n",
      "|    iterations         | 18800     |\n",
      "|    time_elapsed       | 218       |\n",
      "|    total_timesteps    | 94000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000367 |\n",
      "|    explained_variance | -11.6     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 18799     |\n",
      "|    policy_loss        | -2.47e-07 |\n",
      "|    value_loss         | 0.000123  |\n",
      "-------------------------------------\n",
      "--------------------\n",
      "Number of steps:  5840.0\n",
      "Average reward:  0.4\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  5850.0\n",
      "Average reward:  0.25\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  5860.0\n",
      "Average reward:  0.1\n",
      "--------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 430      |\n",
      "|    iterations         | 18900    |\n",
      "|    time_elapsed       | 219      |\n",
      "|    total_timesteps    | 94500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.135   |\n",
      "|    explained_variance | -0.0006  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 18899    |\n",
      "|    policy_loss        | 0.106    |\n",
      "|    value_loss         | 0.214    |\n",
      "------------------------------------\n",
      "--------------------\n",
      "Number of steps:  5870.0\n",
      "Average reward:  0.4\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  5880.0\n",
      "Average reward:  -0.05\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  5890.0\n",
      "Average reward:  0.85\n",
      "--------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 429      |\n",
      "|    iterations         | 19000    |\n",
      "|    time_elapsed       | 220      |\n",
      "|    total_timesteps    | 95000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0831  |\n",
      "|    explained_variance | -2.33    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 18999    |\n",
      "|    policy_loss        | -0.0164  |\n",
      "|    value_loss         | 0.238    |\n",
      "------------------------------------\n",
      "--------------------\n",
      "Number of steps:  5900.0\n",
      "Average reward:  -0.5\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  5910.0\n",
      "Average reward:  -0.2\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  5920.0\n",
      "Average reward:  -0.05\n",
      "--------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 430       |\n",
      "|    iterations         | 19100     |\n",
      "|    time_elapsed       | 222       |\n",
      "|    total_timesteps    | 95500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000301 |\n",
      "|    explained_variance | -0.441    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 19099     |\n",
      "|    policy_loss        | 2.46e-07  |\n",
      "|    value_loss         | 0.000168  |\n",
      "-------------------------------------\n",
      "--------------------\n",
      "Number of steps:  5930.0\n",
      "Average reward:  0.4\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  5940.0\n",
      "Average reward:  -0.2\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  5950.0\n",
      "Average reward:  0.25\n",
      "--------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 430      |\n",
      "|    iterations         | 19200    |\n",
      "|    time_elapsed       | 223      |\n",
      "|    total_timesteps    | 96000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.151   |\n",
      "|    explained_variance | -0.04    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 19199    |\n",
      "|    policy_loss        | 0.474    |\n",
      "|    value_loss         | 0.461    |\n",
      "------------------------------------\n",
      "--------------------\n",
      "Number of steps:  5960.0\n",
      "Average reward:  0.4\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  5970.0\n",
      "Average reward:  0.4\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  5980.0\n",
      "Average reward:  0.85\n",
      "--------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 430      |\n",
      "|    iterations         | 19300    |\n",
      "|    time_elapsed       | 224      |\n",
      "|    total_timesteps    | 96500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00011 |\n",
      "|    explained_variance | 0.712    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 19299    |\n",
      "|    policy_loss        | 1.04e-08 |\n",
      "|    value_loss         | 2.08e-06 |\n",
      "------------------------------------\n",
      "--------------------\n",
      "Number of steps:  5990.0\n",
      "Average reward:  0.4\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  6000.0\n",
      "Average reward:  0.4\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  6010.0\n",
      "Average reward:  -0.05\n",
      "--------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 430       |\n",
      "|    iterations         | 19400     |\n",
      "|    time_elapsed       | 225       |\n",
      "|    total_timesteps    | 97000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000122 |\n",
      "|    explained_variance | -5.54     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 19399     |\n",
      "|    policy_loss        | -1.13e-07 |\n",
      "|    value_loss         | 0.000239  |\n",
      "-------------------------------------\n",
      "--------------------\n",
      "Number of steps:  6020.0\n",
      "Average reward:  0.85\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  6030.0\n",
      "Average reward:  1.0\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  6040.0\n",
      "Average reward:  0.7\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  6050.0\n",
      "Average reward:  0.55\n",
      "--------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 429       |\n",
      "|    iterations         | 19500     |\n",
      "|    time_elapsed       | 226       |\n",
      "|    total_timesteps    | 97500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.69e-05 |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 19499     |\n",
      "|    policy_loss        | 7.57e-08  |\n",
      "|    value_loss         | 0.000689  |\n",
      "-------------------------------------\n",
      "--------------------\n",
      "Number of steps:  6060.0\n",
      "Average reward:  0.1\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  6070.0\n",
      "Average reward:  -0.35\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  6080.0\n",
      "Average reward:  0.4\n",
      "--------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 429       |\n",
      "|    iterations         | 19600     |\n",
      "|    time_elapsed       | 228       |\n",
      "|    total_timesteps    | 98000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.91e-05 |\n",
      "|    explained_variance | -0.301    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 19599     |\n",
      "|    policy_loss        | -4.14e-08 |\n",
      "|    value_loss         | 0.00016   |\n",
      "-------------------------------------\n",
      "--------------------\n",
      "Number of steps:  6090.0\n",
      "Average reward:  -0.05\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  6100.0\n",
      "Average reward:  -0.5\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  6110.0\n",
      "Average reward:  -0.05\n",
      "--------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 429      |\n",
      "|    iterations         | 19700    |\n",
      "|    time_elapsed       | 229      |\n",
      "|    total_timesteps    | 98500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0307  |\n",
      "|    explained_variance | -0.29    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 19699    |\n",
      "|    policy_loss        | -0.00474 |\n",
      "|    value_loss         | 0.225    |\n",
      "------------------------------------\n",
      "--------------------\n",
      "Number of steps:  6120.0\n",
      "Average reward:  0.25\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  6130.0\n",
      "Average reward:  -0.05\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  6140.0\n",
      "Average reward:  0.7\n",
      "--------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 429       |\n",
      "|    iterations         | 19800     |\n",
      "|    time_elapsed       | 230       |\n",
      "|    total_timesteps    | 99000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.23e-05 |\n",
      "|    explained_variance | -4.88     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 19799     |\n",
      "|    policy_loss        | -4.9e-08  |\n",
      "|    value_loss         | 0.000226  |\n",
      "-------------------------------------\n",
      "--------------------\n",
      "Number of steps:  6150.0\n",
      "Average reward:  0.7\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  6160.0\n",
      "Average reward:  0.4\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  6170.0\n",
      "Average reward:  0.55\n",
      "--------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 429       |\n",
      "|    iterations         | 19900     |\n",
      "|    time_elapsed       | 231       |\n",
      "|    total_timesteps    | 99500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.37e-05 |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 19899     |\n",
      "|    policy_loss        | -3.01e-08 |\n",
      "|    value_loss         | 0.00054   |\n",
      "-------------------------------------\n",
      "--------------------\n",
      "Number of steps:  6180.0\n",
      "Average reward:  0.85\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  6190.0\n",
      "Average reward:  0.55\n",
      "--------------------\n",
      "--------------------\n",
      "Number of steps:  6200.0\n",
      "Average reward:  -0.5\n",
      "--------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 430       |\n",
      "|    iterations         | 20000     |\n",
      "|    time_elapsed       | 232       |\n",
      "|    total_timesteps    | 100000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.73e-05 |\n",
      "|    explained_variance | -1.85     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 19999     |\n",
      "|    policy_loss        | -1.19e-09 |\n",
      "|    value_loss         | 0.000291  |\n",
      "-------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# the env is now wrapped automatically when passing it to the constructor\n",
    "model = A2C(\"MlpPolicy\", env, verbose=1, policy_kwargs={'net_arch': [64, 64]})\n",
    "model.learn(total_timesteps=env.conf.agent.training.steps)\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "svUQlptJAVv9"
   },
   "source": [
    "### Visualize results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x480 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# Create task\n",
    "env = gym.make(task, **kwargs)\n",
    "# Apply the wrapper\n",
    "env = TrialHistoryV2(env, probs=probs)\n",
    "env = DummyVecEnv([lambda: env])\n",
    "fig = plotting.plot_env(\n",
    "    env,\n",
    "    num_steps=100,\n",
    "    # def_act=0,\n",
    "    ob_traces=['Fixation cue', 'NoGo', 'Go'],\n",
    "    # fig_kwargs={'figsize': (12, 12)},\n",
    "    model=model)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "example_neurogym_rl.ipynb",
   "provenance": []
  },
  "hide_input": false,
  "kernelspec": {
   "display_name": "neurogym",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
